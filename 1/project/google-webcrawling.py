import re
import json
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# âœ… í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì •
options = webdriver.ChromeOptions()
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36")

# âœ… í¬ë¡¬ ë“œë¼ì´ë²„ ì‹¤í–‰
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

# âœ… 1. êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰ í˜ì´ì§€ë¡œ ì´ë™
search_query = "ìº í•‘ì¹´ íŒë§¤ëŸ‰"
google_news_search_url = f"https://news.google.com/search?q={search_query}&hl=ko&gl=KR&ceid=KR:ko"
driver.get(google_news_search_url)
time.sleep(3)  # ì´ˆê¸° ë¡œë”© ëŒ€ê¸°

# âœ… 2. ë‰´ìŠ¤ ê¸°ì‚¬ ë¡œë“œ ëŒ€ê¸°
try:
    WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, "article"))
    )
    print("âœ… ë‰´ìŠ¤ ëª©ë¡ í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ")
except:
    print("âš ï¸ ë‰´ìŠ¤ ëª©ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    driver.quit()
    exit()

# âœ… 3. ë‰´ìŠ¤ ê¸°ì‚¬ 100ê°œ í¬ë¡¤ë§
news_data = []
news_articles = driver.find_elements(By.CSS_SELECTOR, "article")[:100]  # ìƒìœ„ 100ê°œ ê¸°ì‚¬ ì„ íƒ

for idx, article in enumerate(news_articles, 1):
    try:
        # âœ… ê¸°ì‚¬ ì œëª© ë° ë§í¬ ì¶”ì¶œ
        news_link = article.find_element(By.TAG_NAME, "a")
        news_title = news_link.text.strip()

        WebDriverWait(driver, 10).until(EC.element_to_be_clickable(news_link)).click()
        time.sleep(3)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°

        # âœ… ìƒˆ ì°½ìœ¼ë¡œ ì „í™˜
        driver.switch_to.window(driver.window_handles[-1])

        # âœ… ë‰´ìŠ¤ ë³¸ë¬¸ í¬ë¡¤ë§ (ë‹¤ì–‘í•œ íƒœê·¸ íƒìƒ‰)
        paragraphs = driver.find_elements(By.TAG_NAME, "p")
        if not paragraphs:
            paragraphs = driver.find_elements(By.CSS_SELECTOR, "div")  # ë³¸ë¬¸ì´ <div>ì— ìˆì„ ê²½ìš°
        content = "\n".join([p.text for p in paragraphs if p.text])

        # ğŸ“Œ ë””ë²„ê¹…: ë³¸ë¬¸ í™•ì¸
        print(f"\nğŸ“œ [ê¸°ì‚¬ {idx}] ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°:")
        print(content[:500])  # ë³¸ë¬¸ì´ ì˜ ë‚˜ì˜¤ëŠ”ì§€ ì• 500ì ì¶œë ¥

        # âœ… íŒë§¤ëŸ‰ ë°ì´í„° ì¶”ì¶œ (ì •ê·œì‹ ê°œì„  ì ìš©)
        sales_data_list = []
        sales_pattern = re.findall(r"(\d{4})\s*ë…„[^\d]*(\d{1,3}(?:,\d{3})*|1?\d{1,4})\s*(?:ëŒ€\s*(?:íŒë§¤|ë“±ë¡|ì¶œê³ )?)", content)

        # ğŸ“Œ ë””ë²„ê¹…: ì •ê·œì‹ ë§¤ì¹­ ê²°ê³¼ í™•ì¸
        print(f"ğŸ” [ê¸°ì‚¬ {idx}] ì¶”ì¶œëœ íŒë§¤ëŸ‰ ë°ì´í„°:", sales_pattern)

        for year, sales in sales_pattern:
            sales = sales.replace(",", "").replace("ë§Œ", "0000")  # 1ë§Œ â†’ 10000 ë³€í™˜
            sales_data_list.append(f"{year}ë…„ {int(sales)}ëŒ€ íŒë§¤")  # ë¬¸ìì—´ í˜•íƒœë¡œ ì €ì¥

        # âœ… ë°ì´í„° ì €ì¥
        if sales_data_list:
            news_data.append({
                "ì œëª©": news_title,
                "URL": driver.current_url,
                "íŒë§¤ëŸ‰": "; ".join(sales_data_list)  # ì—¬ëŸ¬ ê°œì¼ ê²½ìš° ì„¸ë¯¸ì½œë¡ (;)ìœ¼ë¡œ êµ¬ë¶„
            })
            print(f"âœ… [ê¸°ì‚¬ {idx}] íŒë§¤ëŸ‰ ë°ì´í„° ì €ì¥ ì„±ê³µ")

        # âœ… ì›ë˜ ì°½ìœ¼ë¡œ ëŒì•„ê°€ê¸°
        driver.close()
        driver.switch_to.window(driver.window_handles[0])

    except Exception as e:
        print(f"âš ï¸ [{idx}] ê¸°ì‚¬ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

# âœ… í¬ë¡¤ë§ ì™„ë£Œ í›„ ë¸Œë¼ìš°ì € ì¢…ë£Œ
driver.quit()

# âœ… 4. ë°ì´í„° ì €ì¥ (JSON íŒŒì¼)
with open("camping_car_sales.json", "w", encoding="utf-8") as f:
    json.dump(news_data, f, ensure_ascii=False, indent=4)

print("\nâœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ: camping_car_sales.json")

# âœ… 5. ìµœì¢… ë°ì´í„° ì¶œë ¥
for news in news_data[:5]:  # ìƒìœ„ 5ê°œ ê¸°ì‚¬ë§Œ ì¶œë ¥
    print("\nğŸ”¹ ì œëª©:", news["ì œëª©"])
    print("ğŸ”— URL:", news["URL"])
    print("ğŸ“Š íŒë§¤ëŸ‰ ë°ì´í„°:", news["íŒë§¤ëŸ‰"])
