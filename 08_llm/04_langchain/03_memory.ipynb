{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d2b5f0",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b14cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv # dotenv 파일을 읽어 환경변수로 설정\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df73bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "\n",
    "class InMemoryHistory(BaseChatMessageHistory):\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "\n",
    "    def add_messages(self, messages):\n",
    "        self.messages.extend(messages)\n",
    "        \n",
    "    def clear(self):\n",
    "        self.messages = []\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fdb1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}  # item(key=session_id, value=InMemoryHistory_인스턴스)\n",
    "\n",
    "def get_by_session_id(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d63f910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'good morning', 'how are you?', 'I am fine', 'Thank you']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_test = get_by_session_id('test')\n",
    "history_test.add_messages(['hello', 'good morning', 'how are you?'])\n",
    "history_test.add_messages(['I am fine', 'Thank you'])\n",
    "\n",
    "history_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2be0315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain의 OpenAI API를 사용하기 위한 클래스\n",
    "from langchain_openai import ChatOpenAI\n",
    "# LangChain의 프롬프트 템플릿을 사용하기 위한 클래스\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# 메시지 기록을 사용하는 Runnable 클래스\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# LangChain의 메시지 템플릿을 사용하기 위한 클래스\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '너는 {skill}를 잘하는 AI 어시스턴트야.'),   # 시스템 메시지\n",
    "    MessagesPlaceholder(variable_name=\"history\"),  # 메시지 기록을 위한 플레이스홀더\n",
    "    ('human', '{query}'),  # 사용자의 질문을 위한 플레이스홀더\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.5)\n",
    "chain = prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37658ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history=get_by_session_id,\n",
    "    input_messages_key='query',\n",
    "    history_messages_key='history'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eb66043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='토끼가 농장에서 나무를 세 그루 키우고 있다니, 정말 귀엽고 재미있는 설정이네요! 어떤 종류의 나무를 키우고 있는지, 혹은 그 나무들에 대해 어떤 이야기가 있는지 궁금합니다. 또는 토끼가 나무를 키우는 이유에 대해서도 이야기해볼까요?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 41, 'total_tokens': 118, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BOi9FD0x8Gkr4BEOxzeGX4jGrY7QO', 'finish_reason': 'stop', 'logprobs': None} id='run-332d74da-da2d-4c1f-abb1-462916c9e488-0' usage_metadata={'input_tokens': 41, 'output_tokens': 77, 'total_tokens': 118, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_history.invoke(\n",
    "    {'skill': '대화', 'query': '토끼는 농장에서 나무를 세 그루 키우고 있습니다.'},\n",
    "    config={'configurable': {'session_id': 'rabbit'}}\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe178880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': ['hello', 'good morning', 'how are you?', 'I am fine', 'Thank you'],\n",
       " 'rabbit': [HumanMessage(content='토끼는 농장에서 나무를 세 그루 키우고 있습니다.', additional_kwargs={}, response_metadata={}), AIMessage(content='토끼가 농장에서 나무를 세 그루 키우고 있다니, 정말 귀엽고 재미있는 설정이네요! 어떤 종류의 나무를 키우고 있는지, 혹은 그 나무들에 대해 어떤 이야기가 있는지 궁금합니다. 또는 토끼가 나무를 키우는 이유에 대해서도 이야기해볼까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 41, 'total_tokens': 118, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BOi9FD0x8Gkr4BEOxzeGX4jGrY7QO', 'finish_reason': 'stop', 'logprobs': None}, id='run-332d74da-da2d-4c1f-abb1-462916c9e488-0', usage_metadata={'input_tokens': 41, 'output_tokens': 77, 'total_tokens': 118, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f3c4664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='토끼가 농장에서 나무를 세 그루 키우고 있다고 하셨으니, 다람쥐가 키우는 나무의 수를 알려주시면 합쳐서 몇 그루의 나무를 키우고 있는지 계산할 수 있을 것 같습니다. 다람쥐가 키우는 나무의 수는 몇 그루인가요?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 80, 'prompt_tokens': 149, 'total_tokens': 229, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BOi9cItIZSGWuVRdXt21CyVLjARVO', 'finish_reason': 'stop', 'logprobs': None} id='run-e71c7072-e350-4c96-b6dd-a2b582b60abc-0' usage_metadata={'input_tokens': 149, 'output_tokens': 80, 'total_tokens': 229, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_history.invoke(\n",
    "    {'skill': '대화', 'query': '토끼와 다람쥐는 합해서 몇 그루의 나무를 키우고 있나요?'},\n",
    "    config={'configurable': {'session_id': 'rabbit'}}\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectordb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
