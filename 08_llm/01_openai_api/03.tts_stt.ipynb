{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXLJgcws_VUq"
   },
   "source": [
    "# TTS (Text To Speech)\n",
    "\n",
    "- TTS모델은 텍스트를 자연스러운 음성으로 변환하는 AI모델이다.\n",
    "  - tts-1 : 실시간 텍스트-음성 변환에 최적화된 최신 모델로 속도에 중점. 텍스트를 음성으로 빠르게 변환하는 기능 제공.\n",
    "  - tts-1-hd : 품질에 최적화된 최신 텍스트-음성 변환 모델로 높은 품질에 중점. 음성의 자연스러움과 선명도 강조.\n",
    "\n",
    "- 음성 선택지\n",
    "  - Alloy: 부드럽고 자연스러운 톤의 음성\n",
    "  - Echo: 명확하고 자신감 있는 음성\n",
    "  - Fable: 이야기 전달에 적합한 서정적인 음성\n",
    "  - Onyx: 전문적이고 신뢰감을 주는 음성\n",
    "  - Nova: 활기차고 에너지 넘치는 음성\n",
    "  - Shimmer: 부드럽고 진정시키는 음성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2116,
     "status": "ok",
     "timestamp": 1744781430246,
     "user": {
      "displayName": "무민",
      "userId": "02633665922162351810"
     },
     "user_tz": -540
    },
    "id": "AoYn0cnKBSha",
    "outputId": "e65daa70-9f24-4e09-ec5e-b16e7f739b57"
   },
   "outputs": [],
   "source": [
    "# !pip install dotenv\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1744781465308,
     "user": {
      "displayName": "무민",
      "userId": "02633665922162351810"
     },
     "user_tz": -540
    },
    "id": "CpL17omGBXpy",
    "outputId": "00667217-de58-4253-b267-5f01d51839c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7381,
     "status": "ok",
     "timestamp": 1744781597373,
     "user": {
      "displayName": "무민",
      "userId": "02633665922162351810"
     },
     "user_tz": -540
    },
    "id": "3-o4GG3jBatp"
   },
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m----> 3\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m지금부터 나 좋아해. 가능하면 진심으로 머리 말고 마음을 기대야지 계속 가면 이 길의 끝에 너 있는 거 맞지 살다가 이 선택이 후회되면 그때 빌게요. 전 후회 안할 자신 있거든요 내가 겪은 세상은 그랬어 너 대신 차은상을 무릎 꿇렸네. 내가 아버지 덕분에 가족을 잃었어요 보험이 내 일생일 순 없잖아요? 사는 게 엿 같잖아요 엄마는 아버지 여자니까 아버지가 책임지세요\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m client\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mspeech\u001b[38;5;241m.\u001b[39mwith_streaming_response\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      8\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtts-1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m     voice\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mash\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39minput_text\n\u001b[0;32m     11\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m response:\n",
      "File \u001b[1;32mc:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\openai\\_client.py:116\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    114\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m     )\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "input_text = \"지금부터 나 좋아해. 가능하면 진심으로 머리 말고 마음을 기대야지 계속 가면 이 길의 끝에 너 있는 거 맞지 살다가 이 선택이 후회되면 그때 빌게요. 전 후회 안할 자신 있거든요 내가 겪은 세상은 그랬어 너 대신 차은상을 무릎 꿇렸네. 내가 아버지 덕분에 가족을 잃었어요 보험이 내 일생일 순 없잖아요? 사는 게 엿 같잖아요 엄마는 아버지 여자니까 아버지가 책임지세요\"\n",
    "\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"ash\",\n",
    "    input=input_text\n",
    ") as response:\n",
    "  response.stream_to_file(\"tts_output.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "878Kiam3_bTB"
   },
   "source": [
    "# STT (Speech To Text)\n",
    "\n",
    "- Whisper는 OpenAI에서 개발한 범용 음성 인식 모델로, 다양한 오디오 데이터셋을 학습하여 다국어 음성인식, 음성 번역, 언어 식별 등의 작업을 수행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2165,
     "status": "ok",
     "timestamp": 1744782244362,
     "user": {
      "displayName": "무민",
      "userId": "02633665922162351810"
     },
     "user_tz": -540
    },
    "id": "yn0b4EJIGeLr",
    "outputId": "8c1065b4-8a03-4a5b-ce60-65b8e4a281ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription(text='지금부터 나 좋아해? 가능하면 진심으로 머리 말고 마음을 기대하지. 계속하면 이 길의 끝에 너 있는 거 맞지 살다가 이 선택이 후회되면 그때 빌게요. 전 후회 안 할 자신 있거든요. 내가 겪은 세상은 그랬어. 너 대신 차은상을 무릎 꿇렸네. 내가 아버지 덕분에 가족을 잃었어요. 보험이 내 일생일 순 없잖아요? 사는 게 엿 같잖아요. 엄마는 아버지 여자니까 아버지가 책임지세요.', logprobs=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "with open(\"tts_output.mp3\", \"rb\") as f:\n",
    "  transcriptions = client.audio.transcriptions.create(\n",
    "      model = 'whisper-1',\n",
    "      file = f\n",
    "  )\n",
    "\n",
    "  print(transcriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gtts\n",
      "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from gtts) (2.32.3)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from gtts) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from click<8.2,>=7.1->gtts) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from requests<3,>=2.27->gtts) (2025.1.31)\n",
      "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: gtts\n",
      "Successfully installed gtts-2.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "\n",
    "tts = gTTS(text=\"안녕하세요. 황준호는 다운입니다.\", lang='ko')\n",
    "\n",
    "tts.save('gtts_output.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Downloading speechrecognition-3.14.2-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (from SpeechRecognition) (4.12.2)\n",
      "Downloading speechrecognition-3.14.2-py3-none-any.whl (32.9 MB)\n",
      "   ---------------------------------------- 0.0/32.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.1/32.9 MB 20.5 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 5.5/32.9 MB 16.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 8.4/32.9 MB 13.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 12.3/32.9 MB 15.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 14.9/32.9 MB 14.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 18.1/32.9 MB 14.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 21.2/32.9 MB 14.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 22.3/32.9 MB 13.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 25.2/32.9 MB 13.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 29.1/32.9 MB 13.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 32.9/32.9 MB 14.8 MB/s eta 0:00:00\n",
      "Installing collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.14.2\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyaudio\n",
      "  Downloading PyAudio-0.2.14-cp312-cp312-win_amd64.whl.metadata (2.7 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading PyAudio-0.2.14-cp312-cp312-win_amd64.whl (164 kB)\n",
      "Installing collected packages: pydub, pyaudio\n",
      "Successfully installed pyaudio-0.2.14 pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말씀하세요.\n",
      "황준호 다운\n",
      "말씀하세요.\n"
     ]
    },
    {
     "ename": "UnknownValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m말씀하세요.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m audio \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mlisten(source)\n\u001b[1;32m----> 9\u001b[0m txt \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mko-KR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(txt)\n",
      "File \u001b[1;32mc:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\speech_recognition\\recognizers\\google.py:262\u001b[0m, in \u001b[0;36mrecognize_legacy\u001b[1;34m(recognizer, audio_data, key, language, pfilter, show_all, with_confidence, endpoint)\u001b[0m\n\u001b[0;32m    255\u001b[0m response_text \u001b[38;5;241m=\u001b[39m obtain_transcription(\n\u001b[0;32m    256\u001b[0m     request, timeout\u001b[38;5;241m=\u001b[39mrecognizer\u001b[38;5;241m.\u001b[39moperation_timeout\n\u001b[0;32m    257\u001b[0m )\n\u001b[0;32m    259\u001b[0m output_parser \u001b[38;5;241m=\u001b[39m OutputParser(\n\u001b[0;32m    260\u001b[0m     show_all\u001b[38;5;241m=\u001b[39mshow_all, with_confidence\u001b[38;5;241m=\u001b[39mwith_confidence\n\u001b[0;32m    261\u001b[0m )\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\speech_recognition\\recognizers\\google.py:134\u001b[0m, in \u001b[0;36mOutputParser.parse\u001b[1;34m(self, response_text)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, response_text: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 134\u001b[0m     actual_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_all:\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m actual_result\n",
      "File \u001b[1;32mc:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\speech_recognition\\recognizers\\google.py:183\u001b[0m, in \u001b[0;36mOutputParser.convert_to_result\u001b[1;34m(response_text)\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n",
      "\u001b[1;31mUnknownValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 음성 입력 -> 텍스트 출력\n",
    "import speech_recognition as sr\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "while True: # 마이크로 부터 음성 입력을 받기 위한 무한 루프\n",
    "    with sr.Microphone() as source: # 마이크로 부터 음성 입력을 감지하기 위한 소스\n",
    "        print(\"듣고 있습니다.\")\n",
    "        print(\"말씀하세요.\")\n",
    "        audio = recognizer.listen(source)   # 음성 데이터를 수집하기 위한 메소드\n",
    "        txt = recognizer.recognize_google(audio, language='ko-KR') # 구글 음성 인식 API를 사용하여 음성을 텍스트로 변환\n",
    "        print(\"인식된 텍스트: \", txt)\n",
    "        print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: pyaudio in c:\\users\\playdata\\appdata\\local\\anaconda3\\envs\\pystudy_env\\lib\\site-packages (0.2.14)\n"
     ]
    }
   ],
   "source": [
    "# !pip install pydub pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'audio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspeech_recognition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msr\u001b[39;00m\n\u001b[0;32m      4\u001b[0m AudioSegment\u001b[38;5;241m.\u001b[39mfrom_mp3(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgtts_output.mp3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43maudio\u001b[49m\u001b[38;5;241m.\u001b[39mexport(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgtts_output_wav.wav\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m r \u001b[38;5;241m=\u001b[39m sr\u001b[38;5;241m.\u001b[39mRecognizer()\n\u001b[0;32m      8\u001b[0m input_audio \u001b[38;5;241m=\u001b[39m sr\u001b[38;5;241m.\u001b[39mAudioFile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgtts_output_wav.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'audio' is not defined"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "\n",
    "AudioSegment.from_mp3('gtts_output.mp3')\n",
    "audio.export('gtts_output_wav.wav', format='wav')\n",
    "\n",
    "r = sr.Recognizer()\n",
    "input_audio = sr.AudioFile('gtts_output_wav.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN+TjdPJraL7HHNorU3fjsJ",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
