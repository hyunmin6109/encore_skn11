{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chat Completion"
      ],
      "metadata": {
        "id": "IVroVy7FdEvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 환경 설정\n",
        "- .env 파일"
      ],
      "metadata": {
        "id": "1NDsTeCddfn_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBYEOFBTc8Qf",
        "outputId": "7cec0303-eae1-46c5-d13f-df15970242a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3eek3p_fbEQ",
        "outputId": "9ecd3529-e59f-4cbe-c8f1-adfad6f83b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "2ncISMTAkPA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat Completion"
      ],
      "metadata": {
        "id": "LeNTjiznk__1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"당신은 친절하고 상세한 설명을 잘하는 챗봇입니다.\"},\n",
        "        {\"role\": \"user\", \"content\": \"안녕하세요. 저는 토끼 선생님입니다.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"안녕하세요. 토끼 선생님. 무엇을 도와드릴까요?\"},\n",
        "        {\"role\": \"user\", \"content\": \"제 이름이 뭐라구요?\"}\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_tokens=4096,\n",
        "    top_p=1\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWC0g_SIkhKg",
        "outputId": "397fed25-d49e-43f8-8d28-c34d4a8fecda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "당신의 이름은 \"토끼 선생님\"이라고 말씀하셨습니다! 혹시 다른 이름이 있으신가요? 아니면 더 알고 싶은 것이 있으신가요?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### stream 처리"
      ],
      "metadata": {
        "id": "GPTM-4S2n0uF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI()\n",
        "\n",
        "stream_response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"stream 테스트를 할건데, 아주 긴 응답 메세지를 보내주세요.\"}\n",
        "    ],\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "for chunk in stream_response:\n",
        "  if chunk.choices[0].delta.content is not None:\n",
        "    print(chunk.choices[0].delta.content, end='')\n",
        "\n",
        "print('👌응답 완료👌')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOZ7HNJZn5TB",
        "outputId": "5c4e11d5-581b-4246-f112-5c80d6265191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "물론입니다! 여기 긴 응답 메시지를 제공합니다.\n",
            "\n",
            "---\n",
            "\n",
            "안녕하세요! 당신이 Stream 테스트를 위해 긴 응답 메시지를 요청하셨군요. 이제부터 다양한 주제를 다루며 긴 내용을 제공합니다.\n",
            "\n",
            "우선, 인공지능(AI)의 발전에 대해서 이야기해봅시다. 인공지능은 과거 몇 년 동안 기하급수적으로 발전해 왔습니다. 초기의 AI는 주로 규칙 기반 시스템으로 이루어져 있었고, 간단한 작업을 수행하는 데에만 한정되어 있었습니다. 그러나 최근 몇 년 간의 연구 결과로, 머신러닝과 딥러닝 기술이 대두되면서 AI는 훨씬 더 복잡한 문제를 해결할 수 있게 되었습니다.\n",
            "\n",
            "예를 들어, 이미지 인식 분야에서 AI는 수천만 개의 이미지를 학습하여 사람의 얼굴, 동물, 사물 등을 인식할 수 있는 능력을 가지게 되었습니다. 이는 자율주행차, 보안 시스템, 의료 진단 등 다양한 분야에서 활용되고 있습니다. 최근에는 자연어 처리(NLP) 분야에서도 AI가 큰 발전을 이루었는데, 이는 사람들이 사용하는 언어를 이해하고 생성하는 능력을 향상시키고 있습니다.\n",
            "\n",
            "또한, AI는 많은 산업에 혁신을 가져왔습니다. 제조업에서는 로봇 공정을 안전하고 효율적으로 관리하는 데 사용되고 있으며, 금융업에서는 고객의 데이터 분석을 통해 맞춤형 서비스를 제공하는 데 기여하고 있습니다. 이 외에도 소매업, 농업, 의료 등 다양한 분야에서 AI는 그 가능성을 보여주고 있습니다.\n",
            "\n",
            "인공지능의 발전이 가져오는 사회적, 윤리적 문제에 대한 논의도 활발하게 이루어지고 있습니다. AI의 자동화로 인한 일자리 감소 우려, 데이터 개인 정보 보호 문제, AI의 편향성과 같은 이슈들이 그것입니다. 이러한 문제들을 해결하기 위해 세계 각국에서는 AI에 대한 규제와 가이드라인을 마련하고 있습니다.\n",
            "\n",
            "이제 다음 주제로 넘어가 볼까요? 환경 문제에 대한 사회적 인식과 대응에 대해 논의해보겠습니다. 최근 몇 년 간 환경 문제는 지구촌이 직면한 가장 큰 도전 중 하나로 부각되고 있습니다. 기후 변화, 해양 오염, 대기 오염 등 다양한 문제들이 발생하고 있으며, 이로 인해 생태계와 인류의 생존에 심각한 위협이 되고 있습니다. \n",
            "\n",
            "이에 따라 많은 국가와 기업들이 지속 가능한 발전을 위한 노력을 기울이고 있습니다. 정부의 정책적 지원과 함께, 개인과 기업의 참여가 중요해지고 있습니다. 예를 들어, 재활용 프로그램, 친환경 제품 개발, 탄소 배출 감소를 위한 노력 등 다양한 형태로 환경 보호를 위한 활동이 이루어지고 있습니다. 또한, 청정 에너지로의 전환 역시 중요한 이슈로 떠오르고 있습니다.\n",
            "\n",
            "마지막으로, 긍정적인 변화와 더불어 사회 전반에 걸쳐 이루어지는 인식 변화도 중요한 요소입니다. 많은 사람들이 환경 보호의 중요성을 인식하게 되었고, 이에 따라 소비 패턴이나 라이프스타일을 변화시키려는 노력을 보이고 있습니다. 이러한 변화는 앞으로 더 많은 사람들에게 확산될 것으로 기대됩니다.\n",
            "\n",
            "이처럼 인공지능과 환경 문제는 현대 사회가 해결해야 할 중요한 주제입니다. 여러 분야에서 긍정적인 변화가 이루어지고 있지만, 우리는 여전히 많은 과제를 안고 있습니다. 이러한 문제들에 대해 함께 고민하고 논의해 나가는 과정이 중요하다고 생각합니다.\n",
            "\n",
            "이 메시지가 Stream 테스트에 유용하게 사용되길 바랍니다! 추가로 필요한 내용이 있으면 언제든지 말씀해 주세요. 감사합니다!\n",
            "\n",
            "--- \n",
            "\n",
            "이렇게 긴 응답이 도움이 되었기를 바랍니다!👌응답 완료👌\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Token Counting\n",
        "\n",
        "- 한번의 프롬프트 입출력 토큰과 서비스 호출 빈도를 고려해 서비스 제공 비용을 산정할 수 있음"
      ],
      "metadata": {
        "id": "9DdGINGIrM5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTO6CmzfrYp_",
        "outputId": "dc96d95d-3bfe-40bd-da63-01861eb2836b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "gpt35_tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "gpt4o_tokenizer = tiktoken.encoding_for_model(\"gpt-4o\")\n",
        "\n",
        "text = \"\"\"\n",
        "KT가 태국 ‘자스민(Jasmine)’ 그룹의 IT 전문 기업 ‘자스민 테크놀로지 솔루션(Jasmine Technology Solutions, 이하 JTS)’과 추진한 태국어 대형언어모델(LLM) 플랫폼 구축 프로젝트를 성공적으로 마무리했다고 15일 밝혔다.\n",
        "\n",
        "KT는 자체 모델 개발 경험과 노하우를 토대로 국내 LLM 전문 기업 업스테이지(대표 김성훈)와 태국어 전용 LLM을 공동 개발했다. 이 모델은 태국어, 영어, 한국어 등을 지원한다. 태국의 방대한 고유 데이터를 학습해 태국 정치, 역사, 문화 관련 질문에도 정확하게 응대할 수 있다.\n",
        "\n",
        "KT는 지난해 3월 JTS와 태국어 LLM 플랫폼 개발 프로젝트를 위한 계약을 체결하고 1년여간 프로젝트를 수행해왔다. 이 프로젝트는 LLM 운영 관리 환경 ‘LLM 옵스(Ops)’와 AI 서비스 인프라 ‘GPU 팜(Farm)’을 구축하고 ‘태국어 전용 ‘LLM 모델’까지 개발하는 원스톱 프로젝트다. 해외에 종합 AI 인프라를 구축해 생성형 AI 서비스의 개발과 운영, 확장 환경을 마련한 것은 국내 기업 중 KT 그룹이 처음이다.\n",
        "\n",
        "LLM 옵스는 다양한 LLM 모델의 학습·배포·운영 전 과정을 관리할 수 있는 환경이다. KT는 이를 고객사 맞춤형으로 구축해 JTS는 복잡한 생성형 AI 운영 환경을 보다 효율적, 안정적으로 운용할 수 있게 됐다.\n",
        "\n",
        "더불어 KT는 클라우드 자회사 KT Cloud와 함께 GPU 자원 관리를 위한 GPU 팜도 태국 현지에 조성했다. 여기에 기반해 JTS는 태국 기업과 기관에 GPU 구독 서비스(GPU as a Service, GPUaaS)를 공급하고 본격적으로 태국 내 AI 생태계 확장을 촉진할 계획이다.\n",
        "\n",
        "한편, KT는 대한민국 AX 생태계 발전을 위해 지난 2023년 업스테이지에 투자했다. 이번 프로젝트는 대기업과 스타트업이 공동으로 글로벌 AX 사업을 성공한 사례로서 의미를 더했다.\n",
        "\n",
        "KT는 앞으로도 JTS의 전문 기술 파트너로서 AI 플랫폼 고도화, GPU 인프라 확장 및 유지 보수, AI 기반 신규 서비스 발굴 등 다분야에서 지속적인 협력을 이어 나간다. 또한 양 사는 태국 AX 시장을 겨냥한 AI 서비스를 단계적으로 선보일 계획이다..\n",
        "\n",
        "KT는 이번 프로젝트로 성공적인 글로벌 AX 사업 레퍼런스를 확보했다. 이를 통해 한층 고도화된 AI 사업 역량을 확보하고 동남아 시장뿐만 아니라 중동, 유럽 등 다른 글로벌 시장까지 AX 사업 영역을 본격적으로 확대해 나갈 방침이다.\n",
        "\n",
        "KT 전략·사업컨설팅부문 AI사업전략담당 이진형 상무는 “태국어 특화 LLM 플랫폼 개발과 상용화는 KT의 AI 기술력과 글로벌 사업 역량을 다시 한번 입증한 성과”라며 “이번 프로젝트에서 얻은 경험과 노하우를 포함해 KT는 마이크로소프트, 팔란티어와의 전략적 제휴를 기반으로 AI, 클라우드의 서비스형 상품 라인업도 다각화해 나갈 계획이다”라고 밝혔다.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "print(len(gpt35_tokenizer.encode(text)))\n",
        "print(len(gpt4o_tokenizer.encode(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CFBnhsFrPy5",
        "outputId": "2cbb035f-88ab-458c-f900-e2b7425240e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1286\n",
            "731\n"
          ]
        }
      ]
    }
  ]
}