{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 비선형 지도학습 분류\n",
    "1. Random Forest\n",
    "2. KNN (k-최근접 이웃)\n",
    "3. SVC (RBF 커널)\n",
    "4. XGBoost / LightGBM \n",
    "5. MLP (다층 퍼셉트론)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/online_retail_customer_churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "def drop_feature(df):\n",
    "    # 식별자 제거\n",
    "    return df.drop('Customer_ID', axis=1)\n",
    "\n",
    "def encode_feature(df):\n",
    "    # 범주형 변수 원핫 인코딩\n",
    "    category = ['Gender', 'Email_Opt_In', 'Promotion_Response']\n",
    "    df_encoded = pd.get_dummies(df, columns=category, drop_first=True)\n",
    "    return df_encoded\n",
    "\n",
    "def remove_gender_other(df):\n",
    "    \"\"\"Gender가 'Other'인 행 제거\"\"\"\n",
    "    df_cleaned = df[df['Gender'] != 'Other'].copy()\n",
    "    return df_cleaned\n",
    "\n",
    "def scale_features(df):\n",
    "    scaler = StandardScaler()\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "    return df\n",
    "\n",
    "def preprocess_for_svm(df):\n",
    "    df = drop_feature(df)\n",
    "    df = remove_gender_other(df)  # Gender 'Other' 제거\n",
    "    df = encode_feature(df)\n",
    "    df = df.dropna()  # 결측치 제거\n",
    "    df = scale_features(df)  # 스케일링 적용\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_df = preprocess_for_svm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Total_Spend</th>\n",
       "      <th>Years_as_Customer</th>\n",
       "      <th>Num_of_Purchases</th>\n",
       "      <th>Average_Transaction_Amount</th>\n",
       "      <th>Num_of_Returns</th>\n",
       "      <th>Num_of_Support_Contacts</th>\n",
       "      <th>Satisfaction_Score</th>\n",
       "      <th>Last_Purchase_Days_Ago</th>\n",
       "      <th>Target_Churn</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Gender_Other</th>\n",
       "      <th>Email_Opt_In_True</th>\n",
       "      <th>Promotion_Response_Responded</th>\n",
       "      <th>Promotion_Response_Unsubscribed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>45.15</td>\n",
       "      <td>5892.58</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>453.80</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>79.51</td>\n",
       "      <td>9025.47</td>\n",
       "      <td>13</td>\n",
       "      <td>77</td>\n",
       "      <td>22.90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>227</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>29.19</td>\n",
       "      <td>618.83</td>\n",
       "      <td>13</td>\n",
       "      <td>71</td>\n",
       "      <td>50.53</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>283</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>79.63</td>\n",
       "      <td>9110.30</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>411.83</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>226</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>77.66</td>\n",
       "      <td>5390.88</td>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "      <td>101.19</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>242</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Annual_Income  Total_Spend  Years_as_Customer  Num_of_Purchases  \\\n",
       "0   62          45.15      5892.58                  5                22   \n",
       "1   65          79.51      9025.47                 13                77   \n",
       "2   18          29.19       618.83                 13                71   \n",
       "3   21          79.63      9110.30                  3                33   \n",
       "4   21          77.66      5390.88                 15                43   \n",
       "\n",
       "   Average_Transaction_Amount  Num_of_Returns  Num_of_Support_Contacts  \\\n",
       "0                      453.80               2                        0   \n",
       "1                       22.90               2                        2   \n",
       "2                       50.53               5                        2   \n",
       "3                      411.83               5                        3   \n",
       "4                      101.19               3                        0   \n",
       "\n",
       "   Satisfaction_Score  Last_Purchase_Days_Ago  Target_Churn  Gender_Male  \\\n",
       "0                   3                     129          True        False   \n",
       "1                   3                     227         False         True   \n",
       "2                   2                     283          True         True   \n",
       "3                   5                     226          True        False   \n",
       "4                   5                     242         False        False   \n",
       "\n",
       "   Gender_Other  Email_Opt_In_True  Promotion_Response_Responded  \\\n",
       "0          True               True                          True   \n",
       "1         False              False                          True   \n",
       "2         False              False                          True   \n",
       "3          True               True                         False   \n",
       "4          True              False                         False   \n",
       "\n",
       "   Promotion_Response_Unsubscribed  \n",
       "0                            False  \n",
       "1                            False  \n",
       "2                            False  \n",
       "3                            False  \n",
       "4                             True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 16 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Age                              1000 non-null   int64  \n",
      " 1   Annual_Income                    1000 non-null   float64\n",
      " 2   Total_Spend                      1000 non-null   float64\n",
      " 3   Years_as_Customer                1000 non-null   int64  \n",
      " 4   Num_of_Purchases                 1000 non-null   int64  \n",
      " 5   Average_Transaction_Amount       1000 non-null   float64\n",
      " 6   Num_of_Returns                   1000 non-null   int64  \n",
      " 7   Num_of_Support_Contacts          1000 non-null   int64  \n",
      " 8   Satisfaction_Score               1000 non-null   int64  \n",
      " 9   Last_Purchase_Days_Ago           1000 non-null   int64  \n",
      " 10  Target_Churn                     1000 non-null   bool   \n",
      " 11  Gender_Male                      1000 non-null   bool   \n",
      " 12  Gender_Other                     1000 non-null   bool   \n",
      " 13  Email_Opt_In_True                1000 non-null   bool   \n",
      " 14  Promotion_Response_Responded     1000 non-null   bool   \n",
      " 15  Promotion_Response_Unsubscribed  1000 non-null   bool   \n",
      "dtypes: bool(6), float64(3), int64(7)\n",
      "memory usage: 84.1 KB\n"
     ]
    }
   ],
   "source": [
    "rt_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target_Churn\n",
       "True     526\n",
       "False    474\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_df['Target_Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "훈련 데이터 정확도: 0.7981\n",
      "평가 데이터 정확도: 0.4485\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.40      0.31      0.35        65\n",
      "        True       0.48      0.58      0.52        71\n",
      "\n",
      "    accuracy                           0.45       136\n",
      "   macro avg       0.44      0.44      0.44       136\n",
      "weighted avg       0.44      0.45      0.44       136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# CSV 파일 로드\n",
    "df = pd.read_csv('./data/online_retail_customer_churn.csv')\n",
    "\n",
    "# 타겟 변수 이름을 'Target_Churn'로 수정\n",
    "target = 'Target_Churn'\n",
    "\n",
    "    # 전처리 적용\n",
    "df_processed = preprocess_for_svm(df)\n",
    "\n",
    "# 타겟 변수와 피처 분리\n",
    "X = df_processed.drop(target, axis=1)\n",
    "y = df_processed[target]\n",
    "# 훈련셋과 테스트셋 분할 (80% 훈련, 20% 테스트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# SVM 모델 학습\n",
    "svm_model = SVC(random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "# 훈련 데이터와 테스트 데이터에 대한 정확도 계산\n",
    "train_accuracy = svm_model.score(X_train, y_train)\n",
    "test_accuracy = svm_model.score(X_test, y_test)\n",
    "\n",
    "# 평가 결과 출력 (Classification Report)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(f'\\n훈련 데이터 정확도: {train_accuracy:.4f}')\n",
    "print(f'평가 데이터 정확도: {test_accuracy:.4f}\\n')\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[원본 데이터] 타겟 변수 분포:\n",
      "Target_Churn\n",
      "True     526\n",
      "False    474\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[훈련 데이터] 타겟 변수 분포 (오버샘플링 전):\n",
      "Target_Churn\n",
      "True     277\n",
      "False    263\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[훈련 데이터] 타겟 변수 분포 (오버샘플링 후):\n",
      "Target_Churn\n",
      "True     277\n",
      "False    277\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVM 모델 성능 (Imbalanced Training Data) ===\n",
      "평가 데이터 정확도: 0.4485\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.40      0.31      0.35        65\n",
      "        True       0.48      0.58      0.52        71\n",
      "\n",
      "    accuracy                           0.45       136\n",
      "   macro avg       0.44      0.44      0.44       136\n",
      "weighted avg       0.44      0.45      0.44       136\n",
      "\n",
      "\n",
      "=== SVM 모델 성능 (Oversampled Training Data) ===\n",
      "평가 데이터 정확도: 0.4779\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.45      0.40      0.42        65\n",
      "        True       0.50      0.55      0.52        71\n",
      "\n",
      "    accuracy                           0.48       136\n",
      "   macro avg       0.47      0.47      0.47       136\n",
      "weighted avg       0.48      0.48      0.48       136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# CSV 파일 로드\n",
    "df = pd.read_csv('./data/online_retail_customer_churn.csv')\n",
    "\n",
    "# 타겟 변수 확인 및 분포 시각화\n",
    "target = 'Target_Churn'\n",
    "print(\"\\n[원본 데이터] 타겟 변수 분포:\")\n",
    "print(df[target].value_counts())\n",
    "\n",
    "df[target].value_counts().plot(kind='bar')\n",
    "plt.title(\"Target_Churn Distribution (Original Data)\")\n",
    "plt.xlabel(\"Churn Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# 전처리 적용 (타겟 변수는 삭제하지 않도록 주의)\n",
    "df_processed = preprocess_for_svm(df)\n",
    "\n",
    "# 타겟 변수와 피처 분리\n",
    "X = df_processed.drop(target, axis=1)\n",
    "y = df_processed[target]\n",
    "\n",
    "# 훈련/테스트 셋 분할 (테스트 셋은 오버샘플링 전 동일하게 유지)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\n[훈련 데이터] 타겟 변수 분포 (오버샘플링 전):\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# 오버샘플링 적용 (훈련 데이터에 한해서)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\n[훈련 데이터] 타겟 변수 분포 (오버샘플링 후):\")\n",
    "print(pd.Series(y_resampled).value_counts())\n",
    "\n",
    "pd.Series(y_resampled).value_counts().plot(kind='bar')\n",
    "plt.title(\"Target_Churn Distribution (After RandomOverSampler)\")\n",
    "plt.xlabel(\"Churn Status\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# SVM 모델 학습 및 성능 비교\n",
    "# ----------------------------\n",
    "\n",
    "# 1. 오버샘플링 전 (imbalanced) 데이터로 모델 학습\n",
    "svm_model_imbalanced = SVC(random_state=42)\n",
    "svm_model_imbalanced.fit(X_train, y_train)\n",
    "y_pred_imbalanced = svm_model_imbalanced.predict(X_test)\n",
    "accuracy_imbalanced = svm_model_imbalanced.score(X_test, y_test)\n",
    "report_imbalanced = classification_report(y_test, y_pred_imbalanced)\n",
    "\n",
    "print(\"=== SVM 모델 성능 (Imbalanced Training Data) ===\")\n",
    "print(f\"평가 데이터 정확도: {accuracy_imbalanced:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report_imbalanced)\n",
    "\n",
    "# 2. 오버샘플링 후 데이터로 모델 학습\n",
    "svm_model_oversampled = SVC(random_state=42)\n",
    "svm_model_oversampled.fit(X_resampled, y_resampled)\n",
    "y_pred_oversampled = svm_model_oversampled.predict(X_test)\n",
    "accuracy_oversampled = svm_model_oversampled.score(X_test, y_test)\n",
    "report_oversampled = classification_report(y_test, y_pred_oversampled)\n",
    "\n",
    "print(\"\\n=== SVM 모델 성능 (Oversampled Training Data) ===\")\n",
    "print(f\"평가 데이터 정확도: {accuracy_oversampled:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report_oversampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-01 11:18:46,239] A new study created in memory with name: no-name-8a324dce-27db-4681-be7b-51dcc284040b\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:46,858] Trial 0 finished with value: 0.48580159419088426 and parameters: {'class_weight': 'balanced', 'n_estimators': 83, 'max_depth': 7, 'min_samples_split': 84, 'min_samples_leaf': 12, 'max_leaf_nodes': 48, 'max_features': 'sqrt', 'max_samples': 0.6187919091962344}. Best is trial 0 with value: 0.48580159419088426.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:47,324] Trial 1 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 55, 'max_depth': 7, 'min_samples_split': 30, 'min_samples_leaf': 23, 'max_leaf_nodes': 74, 'max_features': 'sqrt', 'max_samples': 0.523953089564391}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:48,113] Trial 2 finished with value: 0.4978484004968757 and parameters: {'class_weight': 'balanced', 'n_estimators': 120, 'max_depth': 6, 'min_samples_split': 68, 'min_samples_leaf': 18, 'max_leaf_nodes': 93, 'max_features': 'log2', 'max_samples': 0.676872215522225}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:48,590] Trial 3 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 60, 'max_depth': 4, 'min_samples_split': 20, 'min_samples_leaf': 8, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_samples': 0.6442838076596752}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:49,131] Trial 4 finished with value: 0.5044315427061214 and parameters: {'class_weight': 'balanced', 'n_estimators': 76, 'max_depth': 6, 'min_samples_split': 83, 'min_samples_leaf': 20, 'max_leaf_nodes': 89, 'max_features': 'log2', 'max_samples': 0.6620093461433877}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:49,980] Trial 5 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 138, 'max_depth': 6, 'min_samples_split': 82, 'min_samples_leaf': 5, 'max_leaf_nodes': 55, 'max_features': 'sqrt', 'max_samples': 0.5491297445989386}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:50,488] Trial 6 finished with value: 0.4921322826160167 and parameters: {'class_weight': 'balanced', 'n_estimators': 64, 'max_depth': 6, 'min_samples_split': 47, 'min_samples_leaf': 15, 'max_leaf_nodes': 23, 'max_features': 'log2', 'max_samples': 0.5819970685595872}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:51,252] Trial 7 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 123, 'max_depth': 7, 'min_samples_split': 66, 'min_samples_leaf': 6, 'max_leaf_nodes': 25, 'max_features': 'sqrt', 'max_samples': 0.6003470481482103}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:51,872] Trial 8 finished with value: 0.4910875129425323 and parameters: {'class_weight': 'balanced', 'n_estimators': 91, 'max_depth': 5, 'min_samples_split': 48, 'min_samples_leaf': 26, 'max_leaf_nodes': 73, 'max_features': 'sqrt', 'max_samples': 0.6136599479359839}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:52,753] Trial 9 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 144, 'max_depth': 3, 'min_samples_split': 17, 'min_samples_leaf': 28, 'max_leaf_nodes': 59, 'max_features': 'log2', 'max_samples': 0.6388149860795043}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:53,172] Trial 10 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 51, 'max_depth': 4, 'min_samples_split': 33, 'min_samples_leaf': 23, 'max_leaf_nodes': 75, 'max_features': 'sqrt', 'max_samples': 0.5110971343046551}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:53,621] Trial 11 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 55, 'max_depth': 4, 'min_samples_split': 11, 'min_samples_leaf': 10, 'max_leaf_nodes': 11, 'max_features': 'sqrt', 'max_samples': 0.5053082475737611}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:54,139] Trial 12 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 69, 'max_depth': 4, 'min_samples_split': 26, 'min_samples_leaf': 22, 'max_leaf_nodes': 38, 'max_features': 'sqrt', 'max_samples': 0.5574095724919438}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:54,773] Trial 13 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 92, 'max_depth': 3, 'min_samples_split': 35, 'min_samples_leaf': 30, 'max_leaf_nodes': 71, 'max_features': 'sqrt', 'max_samples': 0.650125970142986}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:55,478] Trial 14 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 107, 'max_depth': 5, 'min_samples_split': 23, 'min_samples_leaf': 14, 'max_leaf_nodes': 84, 'max_features': 'sqrt', 'max_samples': 0.545485704025221}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:55,969] Trial 15 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 64, 'max_depth': 4, 'min_samples_split': 100, 'min_samples_leaf': 9, 'max_leaf_nodes': 100, 'max_features': 'sqrt', 'max_samples': 0.6966351787829642}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:56,408] Trial 16 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 51, 'max_depth': 5, 'min_samples_split': 39, 'min_samples_leaf': 25, 'max_leaf_nodes': 43, 'max_features': 'sqrt', 'max_samples': 0.5804211662763006}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:56,976] Trial 17 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 77, 'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 17, 'max_leaf_nodes': 30, 'max_features': 'sqrt', 'max_samples': 0.5273561468349472}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:57,688] Trial 18 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 105, 'max_depth': 5, 'min_samples_split': 26, 'min_samples_leaf': 20, 'max_leaf_nodes': 63, 'max_features': 'log2', 'max_samples': 0.6258065493266928}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:58,192] Trial 19 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 62, 'max_depth': 3, 'min_samples_split': 53, 'min_samples_leaf': 8, 'max_leaf_nodes': 17, 'max_features': 'sqrt', 'max_samples': 0.5755708890141416}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:58,832] Trial 20 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 89, 'max_depth': 4, 'min_samples_split': 41, 'min_samples_leaf': 12, 'max_leaf_nodes': 51, 'max_features': 'sqrt', 'max_samples': 0.6836342606439068}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:18:59,754] Trial 21 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 150, 'max_depth': 6, 'min_samples_split': 66, 'min_samples_leaf': 5, 'max_leaf_nodes': 36, 'max_features': 'sqrt', 'max_samples': 0.531861804853755}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:00,588] Trial 22 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 133, 'max_depth': 7, 'min_samples_split': 98, 'min_samples_leaf': 7, 'max_leaf_nodes': 80, 'max_features': 'sqrt', 'max_samples': 0.5495838337324841}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:01,350] Trial 23 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 117, 'max_depth': 6, 'min_samples_split': 77, 'min_samples_leaf': 5, 'max_leaf_nodes': 66, 'max_features': 'sqrt', 'max_samples': 0.56420621832119}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:02,202] Trial 24 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 132, 'max_depth': 7, 'min_samples_split': 58, 'min_samples_leaf': 10, 'max_leaf_nodes': 54, 'max_features': 'sqrt', 'max_samples': 0.5197925808802321}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:02,764] Trial 25 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 74, 'max_depth': 6, 'min_samples_split': 18, 'min_samples_leaf': 12, 'max_leaf_nodes': 59, 'max_features': 'sqrt', 'max_samples': 0.5383307682860141}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:03,236] Trial 26 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 59, 'max_depth': 5, 'min_samples_split': 92, 'min_samples_leaf': 8, 'max_leaf_nodes': 10, 'max_features': 'log2', 'max_samples': 0.501515192054323}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:03,884] Trial 27 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 99, 'max_depth': 7, 'min_samples_split': 30, 'min_samples_leaf': 15, 'max_leaf_nodes': 42, 'max_features': 'sqrt', 'max_samples': 0.5973685083612887}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:04,705] Trial 28 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 134, 'max_depth': 6, 'min_samples_split': 57, 'min_samples_leaf': 24, 'max_leaf_nodes': 66, 'max_features': 'sqrt', 'max_samples': 0.5664817606645025}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:05,307] Trial 29 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 84, 'max_depth': 7, 'min_samples_split': 73, 'min_samples_leaf': 20, 'max_leaf_nodes': 46, 'max_features': 'sqrt', 'max_samples': 0.602081632862296}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:06,026] Trial 30 finished with value: 0.501638365334524 and parameters: {'class_weight': 'balanced', 'n_estimators': 110, 'max_depth': 7, 'min_samples_split': 88, 'min_samples_leaf': 11, 'max_leaf_nodes': 33, 'max_features': 'sqrt', 'max_samples': 0.640550523883838}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:06,800] Trial 31 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 123, 'max_depth': 7, 'min_samples_split': 64, 'min_samples_leaf': 6, 'max_leaf_nodes': 25, 'max_features': 'sqrt', 'max_samples': 0.6013235707453433}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:07,578] Trial 32 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 126, 'max_depth': 7, 'min_samples_split': 80, 'min_samples_leaf': 7, 'max_leaf_nodes': 23, 'max_features': 'sqrt', 'max_samples': 0.6216122760191374}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:08,425] Trial 33 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 138, 'max_depth': 6, 'min_samples_split': 69, 'min_samples_leaf': 5, 'max_leaf_nodes': 17, 'max_features': 'sqrt', 'max_samples': 0.5907373282864425}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:09,168] Trial 34 finished with value: 0.48679970838910275 and parameters: {'class_weight': 'balanced', 'n_estimators': 116, 'max_depth': 6, 'min_samples_split': 62, 'min_samples_leaf': 7, 'max_leaf_nodes': 28, 'max_features': 'log2', 'max_samples': 0.5216819625507795}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:10,036] Trial 35 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 140, 'max_depth': 7, 'min_samples_split': 50, 'min_samples_leaf': 17, 'max_leaf_nodes': 92, 'max_features': 'sqrt', 'max_samples': 0.6682272176417484}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:10,840] Trial 36 finished with value: 0.5121552590006828 and parameters: {'class_weight': 'balanced', 'n_estimators': 126, 'max_depth': 6, 'min_samples_split': 73, 'min_samples_leaf': 27, 'max_leaf_nodes': 16, 'max_features': 'log2', 'max_samples': 0.6136032508743772}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:11,757] Trial 37 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 150, 'max_depth': 5, 'min_samples_split': 86, 'min_samples_leaf': 13, 'max_leaf_nodes': 83, 'max_features': 'sqrt', 'max_samples': 0.6573751886039889}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:12,639] Trial 38 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 144, 'max_depth': 7, 'min_samples_split': 45, 'min_samples_leaf': 9, 'max_leaf_nodes': 76, 'max_features': 'log2', 'max_samples': 0.6344077103036013}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:13,163] Trial 39 finished with value: 0.4897152874255424 and parameters: {'class_weight': 'balanced', 'n_estimators': 70, 'max_depth': 4, 'min_samples_split': 18, 'min_samples_leaf': 19, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_samples': 0.54808597903205}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:13,639] Trial 40 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 57, 'max_depth': 6, 'min_samples_split': 72, 'min_samples_leaf': 22, 'max_leaf_nodes': 49, 'max_features': 'sqrt', 'max_samples': 0.5105965056575782}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:14,530] Trial 41 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 144, 'max_depth': 3, 'min_samples_split': 22, 'min_samples_leaf': 29, 'max_leaf_nodes': 61, 'max_features': 'log2', 'max_samples': 0.6478031402785697}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:15,440] Trial 42 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 144, 'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 28, 'max_leaf_nodes': 70, 'max_features': 'log2', 'max_samples': 0.6314427916605869}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:16,249] Trial 43 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 127, 'max_depth': 3, 'min_samples_split': 32, 'min_samples_leaf': 26, 'max_leaf_nodes': 56, 'max_features': 'log2', 'max_samples': 0.6128998127698021}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:16,686] Trial 44 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 50, 'max_depth': 4, 'min_samples_split': 19, 'min_samples_leaf': 30, 'max_leaf_nodes': 87, 'max_features': 'log2', 'max_samples': 0.67473407965039}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:17,509] Trial 45 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 131, 'max_depth': 4, 'min_samples_split': 28, 'min_samples_leaf': 24, 'max_leaf_nodes': 39, 'max_features': 'log2', 'max_samples': 0.6423822279308972}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:18,038] Trial 46 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 67, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_leaf_nodes': 77, 'max_features': 'sqrt', 'max_samples': 0.6586641814434012}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:18,988] Trial 47 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 138, 'max_depth': 5, 'min_samples_split': 38, 'min_samples_leaf': 27, 'max_leaf_nodes': 68, 'max_features': 'sqrt', 'max_samples': 0.5887917944938361}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:19,625] Trial 48 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 95, 'max_depth': 4, 'min_samples_split': 15, 'min_samples_leaf': 9, 'max_leaf_nodes': 100, 'max_features': 'log2', 'max_samples': 0.570847111469981}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:20,350] Trial 49 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 112, 'max_depth': 5, 'min_samples_split': 23, 'min_samples_leaf': 22, 'max_leaf_nodes': 33, 'max_features': 'sqrt', 'max_samples': 0.5560549148604255}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:21,107] Trial 50 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 121, 'max_depth': 3, 'min_samples_split': 35, 'min_samples_leaf': 16, 'max_leaf_nodes': 53, 'max_features': 'sqrt', 'max_samples': 0.5398641940671672}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:21,540] Trial 51 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 54, 'max_depth': 4, 'min_samples_split': 25, 'min_samples_leaf': 23, 'max_leaf_nodes': 75, 'max_features': 'sqrt', 'max_samples': 0.508476933049092}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:22,027] Trial 52 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 61, 'max_depth': 4, 'min_samples_split': 32, 'min_samples_leaf': 21, 'max_leaf_nodes': 73, 'max_features': 'sqrt', 'max_samples': 0.5280003659041212}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:22,491] Trial 53 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 53, 'max_depth': 5, 'min_samples_split': 41, 'min_samples_leaf': 18, 'max_leaf_nodes': 58, 'max_features': 'sqrt', 'max_samples': 0.515982300887704}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:23,061] Trial 54 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 80, 'max_depth': 3, 'min_samples_split': 21, 'min_samples_leaf': 25, 'max_leaf_nodes': 64, 'max_features': 'sqrt', 'max_samples': 0.5389136611576018}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:23,565] Trial 55 finished with value: 0.6618741109270585 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 64, 'max_depth': 6, 'min_samples_split': 15, 'min_samples_leaf': 6, 'max_leaf_nodes': 79, 'max_features': 'sqrt', 'max_samples': 0.6921467641227662}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:24,030] Trial 56 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 59, 'max_depth': 4, 'min_samples_split': 78, 'min_samples_leaf': 8, 'max_leaf_nodes': 82, 'max_features': 'sqrt', 'max_samples': 0.5584803173984955}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:24,700] Trial 57 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 103, 'max_depth': 7, 'min_samples_split': 93, 'min_samples_leaf': 25, 'max_leaf_nodes': 86, 'max_features': 'sqrt', 'max_samples': 0.5152739733237087}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:25,241] Trial 58 finished with value: 0.4674074074074074 and parameters: {'class_weight': 'balanced', 'n_estimators': 73, 'max_depth': 5, 'min_samples_split': 46, 'min_samples_leaf': 29, 'max_leaf_nodes': 46, 'max_features': 'sqrt', 'max_samples': 0.5325539396165938}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:26,133] Trial 59 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 3}, 'n_estimators': 147, 'max_depth': 7, 'min_samples_split': 27, 'min_samples_leaf': 10, 'max_leaf_nodes': 14, 'max_features': 'sqrt', 'max_samples': 0.504826156822235}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:26,559] Trial 60 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 50, 'max_depth': 3, 'min_samples_split': 61, 'min_samples_leaf': 5, 'max_leaf_nodes': 70, 'max_features': 'log2', 'max_samples': 0.6078304968560746}. Best is trial 1 with value: 0.6666550482165678.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:27,011] Trial 61 finished with value: 0.6675438596491227 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 57, 'max_depth': 4, 'min_samples_split': 13, 'min_samples_leaf': 10, 'max_leaf_nodes': 20, 'max_features': 'sqrt', 'max_samples': 0.5249356981768607}. Best is trial 61 with value: 0.6675438596491227.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:27,467] Trial 62 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 56, 'max_depth': 4, 'min_samples_split': 12, 'min_samples_leaf': 11, 'max_leaf_nodes': 27, 'max_features': 'sqrt', 'max_samples': 0.5239502900559935}. Best is trial 61 with value: 0.6675438596491227.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:27,996] Trial 63 finished with value: 0.6648948530266062 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 65, 'max_depth': 4, 'min_samples_split': 21, 'min_samples_leaf': 8, 'max_leaf_nodes': 22, 'max_features': 'sqrt', 'max_samples': 0.5324136016656594}. Best is trial 61 with value: 0.6675438596491227.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:28,462] Trial 64 finished with value: 0.6648711482693578 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 60, 'max_depth': 4, 'min_samples_split': 18, 'min_samples_leaf': 7, 'max_leaf_nodes': 14, 'max_features': 'sqrt', 'max_samples': 0.6243590388700297}. Best is trial 61 with value: 0.6675438596491227.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:29,069] Trial 65 finished with value: 0.6693393764869081 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 86, 'max_depth': 7, 'min_samples_split': 54, 'min_samples_leaf': 6, 'max_leaf_nodes': 96, 'max_features': 'sqrt', 'max_samples': 0.5810835394305897}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:29,675] Trial 66 finished with value: 0.6693393764869081 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 86, 'max_depth': 7, 'min_samples_split': 53, 'min_samples_leaf': 6, 'max_leaf_nodes': 98, 'max_features': 'sqrt', 'max_samples': 0.5810524991395717}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:30,240] Trial 67 finished with value: 0.6693393764869081 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 80, 'max_depth': 7, 'min_samples_split': 54, 'min_samples_leaf': 6, 'max_leaf_nodes': 94, 'max_features': 'sqrt', 'max_samples': 0.5818825806569308}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:30,853] Trial 68 finished with value: 0.6684445219007784 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 86, 'max_depth': 7, 'min_samples_split': 54, 'min_samples_leaf': 6, 'max_leaf_nodes': 96, 'max_features': 'sqrt', 'max_samples': 0.5833141313483148}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:31,484] Trial 69 finished with value: 0.6684445219007784 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 88, 'max_depth': 7, 'min_samples_split': 53, 'min_samples_leaf': 6, 'max_leaf_nodes': 94, 'max_features': 'sqrt', 'max_samples': 0.5825292482061026}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:32,117] Trial 70 finished with value: 0.6675436209998775 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 87, 'max_depth': 7, 'min_samples_split': 51, 'min_samples_leaf': 6, 'max_leaf_nodes': 96, 'max_features': 'sqrt', 'max_samples': 0.5809049802014445}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:32,730] Trial 71 finished with value: 0.6666548127285189 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 87, 'max_depth': 7, 'min_samples_split': 52, 'min_samples_leaf': 6, 'max_leaf_nodes': 96, 'max_features': 'sqrt', 'max_samples': 0.5814185047895984}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:33,379] Trial 72 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 93, 'max_depth': 7, 'min_samples_split': 55, 'min_samples_leaf': 7, 'max_leaf_nodes': 92, 'max_features': 'sqrt', 'max_samples': 0.5898443525862136}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:33,975] Trial 73 finished with value: 0.6630567667987376 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 83, 'max_depth': 7, 'min_samples_split': 49, 'min_samples_leaf': 5, 'max_leaf_nodes': 94, 'max_features': 'sqrt', 'max_samples': 0.5775430597438105}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:34,551] Trial 74 finished with value: 0.6675438596491227 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 78, 'max_depth': 7, 'min_samples_split': 58, 'min_samples_leaf': 6, 'max_leaf_nodes': 98, 'max_features': 'sqrt', 'max_samples': 0.568123854986506}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:35,140] Trial 75 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 78, 'max_depth': 7, 'min_samples_split': 59, 'min_samples_leaf': 9, 'max_leaf_nodes': 98, 'max_features': 'sqrt', 'max_samples': 0.5695966473532448}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:35,737] Trial 76 finished with value: 0.6675438596491227 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 87, 'max_depth': 7, 'min_samples_split': 55, 'min_samples_leaf': 6, 'max_leaf_nodes': 90, 'max_features': 'sqrt', 'max_samples': 0.585132280921855}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:36,309] Trial 77 finished with value: 0.6684445219007784 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 83, 'max_depth': 7, 'min_samples_split': 54, 'min_samples_leaf': 7, 'max_leaf_nodes': 90, 'max_features': 'sqrt', 'max_samples': 0.5951826706295584}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:36,957] Trial 78 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 97, 'max_depth': 7, 'min_samples_split': 43, 'min_samples_leaf': 8, 'max_leaf_nodes': 89, 'max_features': 'sqrt', 'max_samples': 0.5949315493544601}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:37,582] Trial 79 finished with value: 0.6675438596491227 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 91, 'max_depth': 7, 'min_samples_split': 53, 'min_samples_leaf': 7, 'max_leaf_nodes': 96, 'max_features': 'sqrt', 'max_samples': 0.5750051360703811}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:38,141] Trial 80 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 80, 'max_depth': 7, 'min_samples_split': 58, 'min_samples_leaf': 5, 'max_leaf_nodes': 99, 'max_features': 'sqrt', 'max_samples': 0.6072779483667541}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:38,726] Trial 81 finished with value: 0.6675438596491227 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 86, 'max_depth': 7, 'min_samples_split': 55, 'min_samples_leaf': 6, 'max_leaf_nodes': 91, 'max_features': 'sqrt', 'max_samples': 0.5844178682185773}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:39,307] Trial 82 finished with value: 0.6675438596491227 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 80, 'max_depth': 7, 'min_samples_split': 64, 'min_samples_leaf': 7, 'max_leaf_nodes': 90, 'max_features': 'sqrt', 'max_samples': 0.586334824682188}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:39,838] Trial 83 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 74, 'max_depth': 7, 'min_samples_split': 56, 'min_samples_leaf': 6, 'max_leaf_nodes': 88, 'max_features': 'sqrt', 'max_samples': 0.5623272502337726}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:40,438] Trial 84 finished with value: 0.6675436209998775 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 89, 'max_depth': 7, 'min_samples_split': 48, 'min_samples_leaf': 5, 'max_leaf_nodes': 94, 'max_features': 'sqrt', 'max_samples': 0.5947758052505697}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:41,027] Trial 85 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 85, 'max_depth': 7, 'min_samples_split': 60, 'min_samples_leaf': 10, 'max_leaf_nodes': 97, 'max_features': 'sqrt', 'max_samples': 0.574124668701161}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:41,562] Trial 86 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 71, 'max_depth': 7, 'min_samples_split': 54, 'min_samples_leaf': 8, 'max_leaf_nodes': 94, 'max_features': 'sqrt', 'max_samples': 0.6038151199302997}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:42,142] Trial 87 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 83, 'max_depth': 7, 'min_samples_split': 63, 'min_samples_leaf': 9, 'max_leaf_nodes': 85, 'max_features': 'sqrt', 'max_samples': 0.59259151086994}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:42,694] Trial 88 finished with value: 0.6666548127285189 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 77, 'max_depth': 7, 'min_samples_split': 45, 'min_samples_leaf': 7, 'max_leaf_nodes': 93, 'max_features': 'sqrt', 'max_samples': 0.5662438321459781}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:43,359] Trial 89 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 100, 'max_depth': 6, 'min_samples_split': 50, 'min_samples_leaf': 5, 'max_leaf_nodes': 100, 'max_features': 'sqrt', 'max_samples': 0.55539757068127}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:43,968] Trial 90 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 89, 'max_depth': 7, 'min_samples_split': 68, 'min_samples_leaf': 6, 'max_leaf_nodes': 90, 'max_features': 'sqrt', 'max_samples': 0.5976096267823637}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:44,618] Trial 91 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 92, 'max_depth': 7, 'min_samples_split': 53, 'min_samples_leaf': 8, 'max_leaf_nodes': 97, 'max_features': 'sqrt', 'max_samples': 0.5735926719883578}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:45,276] Trial 92 finished with value: 0.6675438596491227 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 95, 'max_depth': 7, 'min_samples_split': 66, 'min_samples_leaf': 7, 'max_leaf_nodes': 94, 'max_features': 'sqrt', 'max_samples': 0.5765845357457028}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:45,895] Trial 93 finished with value: 0.6684445219007784 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 90, 'max_depth': 7, 'min_samples_split': 57, 'min_samples_leaf': 7, 'max_leaf_nodes': 96, 'max_features': 'sqrt', 'max_samples': 0.5845916240033142}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:46,485] Trial 94 finished with value: 0.6684445219007784 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 81, 'max_depth': 7, 'min_samples_split': 57, 'min_samples_leaf': 5, 'max_leaf_nodes': 88, 'max_features': 'sqrt', 'max_samples': 0.5849792550749693}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:47,084] Trial 95 finished with value: 0.6693393764869081 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 82, 'max_depth': 7, 'min_samples_split': 57, 'min_samples_leaf': 5, 'max_leaf_nodes': 87, 'max_features': 'sqrt', 'max_samples': 0.5877884915855035}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:47,715] Trial 96 finished with value: 0.48393247552045116 and parameters: {'class_weight': 'balanced', 'n_estimators': 84, 'max_depth': 7, 'min_samples_split': 57, 'min_samples_leaf': 5, 'max_leaf_nodes': 82, 'max_features': 'sqrt', 'max_samples': 0.5879418816850372}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:48,270] Trial 97 finished with value: 0.6675438596491227 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 75, 'max_depth': 7, 'min_samples_split': 61, 'min_samples_leaf': 5, 'max_leaf_nodes': 88, 'max_features': 'sqrt', 'max_samples': 0.5800279014936488}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:48,831] Trial 98 finished with value: 0.6675438596491227 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 82, 'max_depth': 7, 'min_samples_split': 48, 'min_samples_leaf': 7, 'max_leaf_nodes': 84, 'max_features': 'sqrt', 'max_samples': 0.6002211380759468}. Best is trial 65 with value: 0.6693393764869081.\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 2} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {0: 1, 1: 3} which is of type dict.\n",
      "  warnings.warn(message)\n",
      "[I 2025-04-01 11:19:49,425] Trial 99 finished with value: 0.6666550482165678 and parameters: {'class_weight': {0: 1, 1: 2}, 'n_estimators': 81, 'max_depth': 6, 'min_samples_split': 51, 'min_samples_leaf': 9, 'max_leaf_nodes': 86, 'max_features': 'sqrt', 'max_samples': 0.6162204668376485}. Best is trial 65 with value: 0.6693393764869081.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "RandomForestClassifier.__init__() got an unexpected keyword argument 'n_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 84\u001b[0m\n\u001b[0;32m     76\u001b[0m best_params\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimator\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m70\u001b[39m,\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     81\u001b[0m })\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Train and evaluate the final model\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m best_rf \u001b[38;5;241m=\u001b[39m \u001b[43mRandomForestClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbest_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m best_rf\u001b[38;5;241m.\u001b[39mfit(X_train_resampled, y_train_resampled)\n\u001b[0;32m     86\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best_rf\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n",
      "\u001b[1;31mTypeError\u001b[0m: RandomForestClassifier.__init__() got an unexpected keyword argument 'n_estimator'"
     ]
    }
   ],
   "source": [
    "# Re-import necessary modules due to kernel reset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reload the dataset\n",
    "df = pd.read_csv(\"./data/online_retail_customer_churn.csv\")\n",
    "\n",
    "# Drop identifier and rows with 'Other' gender\n",
    "df = df[df['Gender'] != 'Other']\n",
    "df = df.drop('Customer_ID', axis=1)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "df = pd.get_dummies(df, columns=['Gender', 'Email_Opt_In', 'Promotion_Response'], drop_first=True)\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(\"Target_Churn\", axis=1)\n",
    "y = df[\"Target_Churn\"].astype(int)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Scale numerical features\n",
    "numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "# Apply SMOTE\n",
    "# smote = SMOTE(random_state=42, sampling_strategy={0:5000, 1:5000})\n",
    "smote = SMOTE(random_state=42, sampling_strategy='auto')\n",
    "# smote = SMOTE(random_state=42, sampling_strategy='minority')\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Define Optuna objective\n",
    "def objective(trial):\n",
    "    # 여기에 추가!\n",
    "    class_weight = trial.suggest_categorical(\n",
    "        \"class_weight\",\n",
    "        ['balanced', {0: 1, 1: 2}, {0: 1, 1: 3}]\n",
    "    )\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 50, 150),\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 3, 7),\n",
    "        min_samples_split=trial.suggest_int(\"min_samples_split\", 10, 100),\n",
    "        min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 5, 30),\n",
    "        max_leaf_nodes=trial.suggest_int(\"max_leaf_nodes\", 10, 100),\n",
    "        max_features=trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"]),\n",
    "        max_samples=trial.suggest_float(\"max_samples\", 0.5, 0.7),\n",
    "        bootstrap=True,\n",
    "        class_weight=class_weight,  # 👉 이 부분에 반영됨\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    score = cross_val_score(model, X_train_resampled, y_train_resampled, scoring=\"f1\", cv=cv)\n",
    "    return score.mean()\n",
    "\n",
    "\n",
    "# Run Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Update best parameters with overrides\n",
    "best_params = study.best_trial.params.copy()\n",
    "best_params.update({\n",
    "    \"max_depth\": 3,\n",
    "    \"n_estimator\": 70,\n",
    "    \"class_weight\": \"balanced\",\n",
    "    \"random_state\": 42\n",
    "})\n",
    "\n",
    "# Train and evaluate the final model\n",
    "best_rf = RandomForestClassifier(**best_params)\n",
    "best_rf.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "{\n",
    "    \"Best_Params\": best_params,\n",
    "    \"Train_Accuracy\": best_rf.score(X_train_resampled, y_train_resampled),\n",
    "    \"Test_Accuracy\": accuracy,\n",
    "    \"Confusion_Matrix\": conf_matrix,\n",
    "    \"Classification_Report\": report\n",
    "}\n",
    "\n",
    "# 평가 결과 출력\n",
    "print(\"\\n[Random Forest 최종 모델 성능 평가]\")\n",
    "print(\"Best Parameters:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"  - {k}: {v}\")\n",
    "\n",
    "print(f\"\\n훈련 정확도: {best_rf.score(X_train_resampled, y_train_resampled):.3f}\")\n",
    "print(f\"테스트 정확도: {accuracy:.3f}\")\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "conf_df = pd.DataFrame(\n",
    "    conf_matrix,\n",
    "    index=[\"Actual: 0 (비이탈)\", \"Actual: 1 (이탈)\"],\n",
    "    columns=[\"Predicted: 0\", \"Predicted: 1\"]\n",
    ")\n",
    "display(conf_df)\n",
    "\n",
    "# 분류 리포트 출력\n",
    "print(\"\\nClassification Report:\")\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "display(report_df.round(3))\n",
    "\n",
    "importances = best_rf.feature_importances_\n",
    "feat_names = X.columns\n",
    "feat_imp = pd.Series(importances, index=feat_names).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "feat_imp.head(15).plot(kind='barh')\n",
    "plt.title(\"Top 15 Feature Importances\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Total_Spend</th>\n",
       "      <th>Years_as_Customer</th>\n",
       "      <th>Num_of_Purchases</th>\n",
       "      <th>Average_Transaction_Amount</th>\n",
       "      <th>Num_of_Returns</th>\n",
       "      <th>Num_of_Support_Contacts</th>\n",
       "      <th>Satisfaction_Score</th>\n",
       "      <th>Last_Purchase_Days_Ago</th>\n",
       "      <th>Email_Opt_In</th>\n",
       "      <th>Promotion_Response</th>\n",
       "      <th>Target_Churn</th>\n",
       "      <th>Spend_to_Income_Ratio</th>\n",
       "      <th>Return_Rate</th>\n",
       "      <th>Support_per_Purchase</th>\n",
       "      <th>Avg_Spend_vs_Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>Male</td>\n",
       "      <td>79.51</td>\n",
       "      <td>9025.47</td>\n",
       "      <td>13</td>\n",
       "      <td>77</td>\n",
       "      <td>22.90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>227</td>\n",
       "      <td>False</td>\n",
       "      <td>Responded</td>\n",
       "      <td>False</td>\n",
       "      <td>0.113512</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.002537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>29.19</td>\n",
       "      <td>618.83</td>\n",
       "      <td>13</td>\n",
       "      <td>71</td>\n",
       "      <td>50.53</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>283</td>\n",
       "      <td>False</td>\n",
       "      <td>Responded</td>\n",
       "      <td>True</td>\n",
       "      <td>0.021199</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.081522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "      <td>Male</td>\n",
       "      <td>190.43</td>\n",
       "      <td>255.19</td>\n",
       "      <td>19</td>\n",
       "      <td>85</td>\n",
       "      <td>417.78</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>False</td>\n",
       "      <td>Unsubscribed</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.058140</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>1.630743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>172.13</td>\n",
       "      <td>3512.55</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>316.18</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>True</td>\n",
       "      <td>Unsubscribed</td>\n",
       "      <td>False</td>\n",
       "      <td>0.020406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.089989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>54</td>\n",
       "      <td>Male</td>\n",
       "      <td>138.90</td>\n",
       "      <td>4283.84</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>96.55</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>True</td>\n",
       "      <td>Responded</td>\n",
       "      <td>False</td>\n",
       "      <td>0.030841</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.022533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Gender  Annual_Income  Total_Spend  Years_as_Customer  \\\n",
       "1    65   Male          79.51      9025.47                 13   \n",
       "2    18   Male          29.19       618.83                 13   \n",
       "5    57   Male         190.43       255.19                 19   \n",
       "6    27   Male         172.13      3512.55                  3   \n",
       "10   54   Male         138.90      4283.84                 15   \n",
       "\n",
       "    Num_of_Purchases  Average_Transaction_Amount  Num_of_Returns  \\\n",
       "1                 77                       22.90               2   \n",
       "2                 71                       50.53               5   \n",
       "5                 85                      417.78               5   \n",
       "6                 77                      316.18               0   \n",
       "10                33                       96.55               9   \n",
       "\n",
       "    Num_of_Support_Contacts  Satisfaction_Score  Last_Purchase_Days_Ago  \\\n",
       "1                         2                   3                     227   \n",
       "2                         2                   2                     283   \n",
       "5                         1                   4                     130   \n",
       "6                         3                   1                      61   \n",
       "10                        1                   2                      92   \n",
       "\n",
       "    Email_Opt_In Promotion_Response  Target_Churn  Spend_to_Income_Ratio  \\\n",
       "1          False          Responded         False               0.113512   \n",
       "2          False          Responded          True               0.021199   \n",
       "5          False       Unsubscribed         False               0.001340   \n",
       "6           True       Unsubscribed         False               0.020406   \n",
       "10          True          Responded         False               0.030841   \n",
       "\n",
       "    Return_Rate  Support_per_Purchase  Avg_Spend_vs_Total  \n",
       "1      0.025641              0.025641            0.002537  \n",
       "2      0.069444              0.027778            0.081522  \n",
       "5      0.058140              0.011628            1.630743  \n",
       "6      0.000000              0.038462            0.089989  \n",
       "10     0.264706              0.029412            0.022533  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"./data/online_retail_customer_churn.csv\")\n",
    "\n",
    "# Drop 'Other' gender and 'Customer_ID'\n",
    "df = df[df['Gender'] != 'Other']\n",
    "df = df.drop('Customer_ID', axis=1)\n",
    "\n",
    "# Create new engineered features\n",
    "df['Spend_to_Income_Ratio'] = df['Total_Spend'] / (df['Annual_Income'] * 1000 + 1)\n",
    "df['Return_Rate'] = df['Num_of_Returns'] / (df['Num_of_Purchases'] + 1)\n",
    "df['Support_per_Purchase'] = df['Num_of_Support_Contacts'] / (df['Num_of_Purchases'] + 1)\n",
    "df['Avg_Spend_vs_Total'] = df['Average_Transaction_Amount'] / (df['Total_Spend'] + 1)\n",
    "\n",
    "# Display a sample\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SVM 모델 성능 평가 - 파생 변수 포함]\n",
      "훈련 정확도: 0.753\n",
      "평가 정확도: 0.517\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted: 0  Predicted: 1\n",
      "Actual: 0 (비이탈)            32            75\n",
      "Actual: 1 (이탈)             23            73\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.30      0.40       107\n",
      "           1       0.49      0.76      0.60        96\n",
      "\n",
      "    accuracy                           0.52       203\n",
      "   macro avg       0.54      0.53      0.50       203\n",
      "weighted avg       0.54      0.52      0.49       203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 1. 데이터 로드\n",
    "df = pd.read_csv(\"./data/online_retail_customer_churn.csv\")\n",
    "\n",
    "# 2. 전처리 함수 정의\n",
    "def preprocess(df):\n",
    "    df = df.drop(columns=['Customer_ID'], errors='ignore')\n",
    "    df = df[df['Gender'] != 'Other'].copy()\n",
    "\n",
    "    # 파생 변수 생성\n",
    "    df['Spend_to_Income_Ratio'] = df['Total_Spend'] / (df['Annual_Income'] * 1000 + 1)\n",
    "    df['Return_Rate'] = df['Num_of_Returns'] / (df['Num_of_Purchases'] + 1)\n",
    "    df['Support_per_Purchase'] = df['Num_of_Support_Contacts'] / (df['Num_of_Purchases'] + 1)\n",
    "    df['Avg_Spend_vs_Total'] = df['Average_Transaction_Amount'] / (df['Total_Spend'] + 1)\n",
    "\n",
    "    # 원핫 인코딩\n",
    "    df = pd.get_dummies(df, columns=['Gender', 'Email_Opt_In', 'Promotion_Response'], drop_first=True)\n",
    "    return df\n",
    "\n",
    "# 3. 전처리 적용\n",
    "df = preprocess(df)\n",
    "\n",
    "# 4. 특성과 타겟 분리\n",
    "X = df.drop(\"Target_Churn\", axis=1)\n",
    "y = df[\"Target_Churn\"].astype(int)\n",
    "\n",
    "# 5. 훈련/테스트 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# 6. 수치형 피처만 스케일링\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "# 7. SVM 모델 학습\n",
    "svm_model = SVC(probability=True, random_state=0)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 8. 예측\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# 9. 성능 출력\n",
    "print(\"\\n[SVM 모델 성능 평가 - 파생 변수 포함]\")\n",
    "print(f\"훈련 정확도: {svm_model.score(X_train_scaled, y_train):.3f}\")\n",
    "print(f\"평가 정확도: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "\n",
    "# 혼동 행렬\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "conf_df = pd.DataFrame(conf_matrix, \n",
    "                       index=[\"Actual: 0 (비이탈)\", \"Actual: 1 (이탈)\"],\n",
    "                       columns=[\"Predicted: 0\", \"Predicted: 1\"])\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_df)\n",
    "\n",
    "# 리포트\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SVM 모델 성능 평가 - 과적합 완화]\n",
      "훈련 정확도: 0.537\n",
      "테스트 정확도: 0.473\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  1 106]\n",
      " [  1  95]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.01      0.02       107\n",
      "           1       0.47      0.99      0.64        96\n",
      "\n",
      "    accuracy                           0.47       203\n",
      "   macro avg       0.49      0.50      0.33       203\n",
      "weighted avg       0.49      0.47      0.31       203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 💡 과적합 완화: C를 줄이고 gamma는 적당히 (C 작을수록 규제 강화)\n",
    "svm_model = SVC(C=0.5, gamma=0.01, kernel='rbf', probability=True, random_state=0)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# 평가 출력\n",
    "print(\"[SVM 모델 성능 평가 - 과적합 완화]\")\n",
    "print(f\"훈련 정확도: {svm_model.score(X_train_scaled, y_train):.3f}\")\n",
    "print(f\"테스트 정확도: {svm_model.score(X_test_scaled, y_test):.3f}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SVM + LogisticRegression + RandomForest - Soft Voting 앙상블 결과]\n",
      "훈련 정확도: 0.5200845665961945\n",
      "테스트 정확도: 0.5221674876847291\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted: 0  Predicted: 1\n",
      "Actual: 0 (비이탈)            30            77\n",
      "Actual: 1 (이탈)             20            76\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.28      0.38       107\n",
      "           1       0.50      0.79      0.61        96\n",
      "\n",
      "    accuracy                           0.52       203\n",
      "   macro avg       0.55      0.54      0.50       203\n",
      "weighted avg       0.55      0.52      0.49       203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# 1. 데이터 불러오기 및 전처리\n",
    "df = pd.read_csv('./data/online_retail_customer_churn.csv')\n",
    "\n",
    "# 불필요한 컬럼 및 'Other' 성별 제거\n",
    "df = df[df['Gender'] != 'Other']\n",
    "df.drop(columns=['Customer_ID'], inplace=True)\n",
    "\n",
    "# 원-핫 인코딩\n",
    "df = pd.get_dummies(df, columns=['Gender', 'Email_Opt_In', 'Promotion_Response'], drop_first=True)\n",
    "\n",
    "# 특성과 타겟 분리\n",
    "X = df.drop(\"Target_Churn\", axis=1)\n",
    "y = df[\"Target_Churn\"].astype(int)\n",
    "\n",
    "# 훈련/테스트 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# 수치형 피처 스케일링\n",
    "numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "# 2. 각 개별 모델 정의\n",
    "svm = SVC(C=1.0, gamma=0.15, kernel='rbf', probability=True, class_weight='balanced', random_state=0)\n",
    "logreg = LogisticRegression(C=1.0, max_iter=1000, class_weight='balanced', solver='liblinear', random_state=0)\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=4, class_weight='balanced', random_state=0)\n",
    "\n",
    "# 3. VotingClassifier 정의 (soft voting)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('svm', svm), ('logreg', logreg), ('rf', rf)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# 4. 학습 및 예측\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "y_pred = voting_clf.predict(X_test_scaled)\n",
    "\n",
    "# 5. 평가\n",
    "print(\"\\n[SVM + LogisticRegression + RandomForest - Soft Voting 앙상블 결과]\")\n",
    "print(\"훈련 정확도:\", voting_clf.score(X_train_scaled, y_train))\n",
    "print(\"테스트 정확도:\", voting_clf.score(X_test_scaled, y_test))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "conf_df = pd.DataFrame(\n",
    "    conf_matrix,\n",
    "    index=[\"Actual: 0 (비이탈)\", \"Actual: 1 (이탈)\"],\n",
    "    columns=[\"Predicted: 0\", \"Predicted: 1\"]\n",
    ")\n",
    "print(conf_df)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.28      0.38       107\n",
      "           1       0.50      0.79      0.61        96\n",
      "\n",
      "    accuracy                           0.52       203\n",
      "   macro avg       0.55      0.54      0.50       203\n",
      "weighted avg       0.55      0.52      0.49       203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# 모델 구성 - SVM, Logistic Regression, Random Forest\n",
    "svm_best = SVC(C=1.0, gamma=0.1, kernel='rbf', class_weight='balanced', probability=True, random_state=0)\n",
    "logreg = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=0)\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=80, max_depth=4, min_samples_split=10,\n",
    "    min_samples_leaf=8, max_leaf_nodes=80, max_features='sqrt',\n",
    "    max_samples=0.75, class_weight='balanced', random_state=42\n",
    ")\n",
    "\n",
    "# 앙상블 모델 구성 - VotingClassifier (SVM 중심, 균형적 가중치로 재튜닝)\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[('svm', svm_best), ('logreg', logreg), ('rf', rf)],\n",
    "    voting='soft',\n",
    "    weights=[1, 3, 1]\n",
    ")\n",
    "\n",
    "# 학습 및 예측\n",
    "voting_model.fit(X_train_scaled, y_train)\n",
    "y_pred_voting = voting_model.predict(X_test_scaled)\n",
    "\n",
    "# 정확도 계산\n",
    "train_score = voting_model.score(X_train_scaled, y_train)\n",
    "test_score = voting_model.score(X_test_scaled, y_test)\n",
    "\n",
    "# 평가 지표\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_voting)\n",
    "report = classification_report(y_test, y_pred_voting, output_dict=True)\n",
    "\n",
    "# 정리된 결과 출력용\n",
    "conf_matrix_df = pd.DataFrame(\n",
    "    conf_matrix,\n",
    "    index=[\"Actual: 0 (비이탈)\", \"Actual: 1 (이탈)\"],\n",
    "    columns=[\"Predicted: 0\", \"Predicted: 1\"]\n",
    ")\n",
    "\n",
    "report_df = pd.DataFrame(report).transpose().round(3)\n",
    "\n",
    "train_score, test_score, conf_matrix_df, report_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-01 11:08:31,282] A new study created in memory with name: no-name-6e10ee28-ab49-4dc5-880a-c22af9a9851e\n",
      "[I 2025-04-01 11:08:31,933] Trial 0 finished with value: 0.5060971422456578 and parameters: {'svm_C': 1.8984474343684894, 'svm_gamma': 0.02402991114805332, 'rf_n_estimators': 99, 'rf_max_depth': 6, 'w_svm': 3, 'w_log': 3, 'w_rf': 2}. Best is trial 0 with value: 0.5060971422456578.\n",
      "[I 2025-04-01 11:08:32,397] Trial 1 finished with value: 0.49434515568742726 and parameters: {'svm_C': 0.5649245769176151, 'svm_gamma': 0.004314583209839687, 'rf_n_estimators': 67, 'rf_max_depth': 3, 'w_svm': 3, 'w_log': 2, 'w_rf': 2}. Best is trial 0 with value: 0.5060971422456578.\n",
      "[I 2025-04-01 11:08:32,816] Trial 2 finished with value: 0.5142249354201356 and parameters: {'svm_C': 0.19780016746827586, 'svm_gamma': 0.014309631918260837, 'rf_n_estimators': 51, 'rf_max_depth': 6, 'w_svm': 3, 'w_log': 3, 'w_rf': 2}. Best is trial 2 with value: 0.5142249354201356.\n",
      "[I 2025-04-01 11:08:33,297] Trial 3 finished with value: 0.5360789752370844 and parameters: {'svm_C': 3.2848216099722496, 'svm_gamma': 0.06527627481707808, 'rf_n_estimators': 68, 'rf_max_depth': 4, 'w_svm': 1, 'w_log': 3, 'w_rf': 2}. Best is trial 3 with value: 0.5360789752370844.\n",
      "[I 2025-04-01 11:08:33,747] Trial 4 finished with value: 0.4982889216525983 and parameters: {'svm_C': 0.11117515883049049, 'svm_gamma': 0.09385103475945888, 'rf_n_estimators': 62, 'rf_max_depth': 4, 'w_svm': 3, 'w_log': 2, 'w_rf': 2}. Best is trial 3 with value: 0.5360789752370844.\n",
      "[I 2025-04-01 11:08:34,135] Trial 5 finished with value: 0.4935037446532965 and parameters: {'svm_C': 3.6302713975527587, 'svm_gamma': 0.001876279319604148, 'rf_n_estimators': 50, 'rf_max_depth': 4, 'w_svm': 3, 'w_log': 2, 'w_rf': 3}. Best is trial 3 with value: 0.5360789752370844.\n",
      "[I 2025-04-01 11:08:34,731] Trial 6 finished with value: 0.5107793337510284 and parameters: {'svm_C': 3.591785228271357, 'svm_gamma': 0.004881919555637082, 'rf_n_estimators': 97, 'rf_max_depth': 3, 'w_svm': 2, 'w_log': 2, 'w_rf': 3}. Best is trial 3 with value: 0.5360789752370844.\n",
      "[I 2025-04-01 11:08:35,313] Trial 7 finished with value: 0.5110403882226245 and parameters: {'svm_C': 0.7947857727441173, 'svm_gamma': 0.058418377854736143, 'rf_n_estimators': 91, 'rf_max_depth': 3, 'w_svm': 2, 'w_log': 1, 'w_rf': 1}. Best is trial 3 with value: 0.5360789752370844.\n",
      "[I 2025-04-01 11:08:35,897] Trial 8 finished with value: 0.5250328147427005 and parameters: {'svm_C': 4.480442715139476, 'svm_gamma': 0.025967399188223047, 'rf_n_estimators': 91, 'rf_max_depth': 4, 'w_svm': 3, 'w_log': 1, 'w_rf': 3}. Best is trial 3 with value: 0.5360789752370844.\n",
      "[I 2025-04-01 11:08:36,448] Trial 9 finished with value: 0.5290306511743417 and parameters: {'svm_C': 0.6231599844093163, 'svm_gamma': 0.002780705032291586, 'rf_n_estimators': 82, 'rf_max_depth': 4, 'w_svm': 2, 'w_log': 3, 'w_rf': 1}. Best is trial 3 with value: 0.5360789752370844.\n",
      "[I 2025-04-01 11:08:36,994] Trial 10 finished with value: 0.5366138546082804 and parameters: {'svm_C': 1.414757393260942, 'svm_gamma': 0.04657124299585483, 'rf_n_estimators': 73, 'rf_max_depth': 5, 'w_svm': 1, 'w_log': 3, 'w_rf': 1}. Best is trial 10 with value: 0.5366138546082804.\n",
      "[I 2025-04-01 11:08:37,544] Trial 11 finished with value: 0.5342746028150425 and parameters: {'svm_C': 1.4066230255867078, 'svm_gamma': 0.04399236680288724, 'rf_n_estimators': 74, 'rf_max_depth': 5, 'w_svm': 1, 'w_log': 3, 'w_rf': 1}. Best is trial 10 with value: 0.5366138546082804.\n",
      "[I 2025-04-01 11:08:38,075] Trial 12 finished with value: 0.5366594393609555 and parameters: {'svm_C': 1.6790490502143491, 'svm_gamma': 0.085645640201387, 'rf_n_estimators': 74, 'rf_max_depth': 5, 'w_svm': 1, 'w_log': 3, 'w_rf': 1}. Best is trial 12 with value: 0.5366594393609555.\n",
      "[I 2025-04-01 11:08:38,654] Trial 13 finished with value: 0.5323839868252913 and parameters: {'svm_C': 1.5533115575421939, 'svm_gamma': 0.02973803271321535, 'rf_n_estimators': 79, 'rf_max_depth': 5, 'w_svm': 1, 'w_log': 3, 'w_rf': 1}. Best is trial 12 with value: 0.5366594393609555.\n",
      "[I 2025-04-01 11:08:39,109] Trial 14 finished with value: 0.5285611050661052 and parameters: {'svm_C': 1.1059908013249151, 'svm_gamma': 0.011354636978789561, 'rf_n_estimators': 60, 'rf_max_depth': 5, 'w_svm': 1, 'w_log': 3, 'w_rf': 1}. Best is trial 12 with value: 0.5366594393609555.\n",
      "[I 2025-04-01 11:08:39,659] Trial 15 finished with value: 0.517339052106301 and parameters: {'svm_C': 0.3921596273127982, 'svm_gamma': 0.08877979823207206, 'rf_n_estimators': 74, 'rf_max_depth': 6, 'w_svm': 1, 'w_log': 2, 'w_rf': 1}. Best is trial 12 with value: 0.5366594393609555.\n",
      "[I 2025-04-01 11:08:40,248] Trial 16 finished with value: 0.5323412288913751 and parameters: {'svm_C': 2.3190124941421923, 'svm_gamma': 0.039561154805211766, 'rf_n_estimators': 82, 'rf_max_depth': 5, 'w_svm': 1, 'w_log': 3, 'w_rf': 1}. Best is trial 12 with value: 0.5366594393609555.\n",
      "[I 2025-04-01 11:08:40,759] Trial 17 finished with value: 0.4895719807180642 and parameters: {'svm_C': 2.3844130687371554, 'svm_gamma': 0.017583371090692877, 'rf_n_estimators': 69, 'rf_max_depth': 5, 'w_svm': 2, 'w_log': 1, 'w_rf': 1}. Best is trial 12 with value: 0.5366594393609555.\n",
      "[I 2025-04-01 11:08:41,397] Trial 18 finished with value: 0.5153131701039804 and parameters: {'svm_C': 0.3612701925096933, 'svm_gamma': 0.006017378521955046, 'rf_n_estimators': 88, 'rf_max_depth': 6, 'w_svm': 1, 'w_log': 2, 'w_rf': 2}. Best is trial 12 with value: 0.5366594393609555.\n",
      "[I 2025-04-01 11:08:41,878] Trial 19 finished with value: 0.5150110212907235 and parameters: {'svm_C': 0.8650858771741551, 'svm_gamma': 0.008365402606584289, 'rf_n_estimators': 62, 'rf_max_depth': 5, 'w_svm': 2, 'w_log': 3, 'w_rf': 1}. Best is trial 12 with value: 0.5366594393609555.\n",
      "[I 2025-04-01 11:08:42,425] Trial 20 finished with value: 0.5280153853671022 and parameters: {'svm_C': 1.4547436523248314, 'svm_gamma': 0.053523190655165434, 'rf_n_estimators': 76, 'rf_max_depth': 6, 'w_svm': 1, 'w_log': 3, 'w_rf': 1}. Best is trial 12 with value: 0.5366594393609555.\n",
      "[I 2025-04-01 11:08:42,938] Trial 21 finished with value: 0.5340305377463749 and parameters: {'svm_C': 2.656587087284277, 'svm_gamma': 0.06544931545285622, 'rf_n_estimators': 69, 'rf_max_depth': 4, 'w_svm': 1, 'w_log': 3, 'w_rf': 2}. Best is trial 12 with value: 0.5366594393609555.\n",
      "[I 2025-04-01 11:08:43,481] Trial 22 finished with value: 0.5158846921714344 and parameters: {'svm_C': 4.985856917293996, 'svm_gamma': 0.09286504847909643, 'rf_n_estimators': 66, 'rf_max_depth': 5, 'w_svm': 1, 'w_log': 3, 'w_rf': 3}. Best is trial 12 with value: 0.5366594393609555.\n",
      "[I 2025-04-01 11:08:43,972] Trial 23 finished with value: 0.5341826076578873 and parameters: {'svm_C': 1.0598153068342637, 'svm_gamma': 0.036055093293544456, 'rf_n_estimators': 72, 'rf_max_depth': 4, 'w_svm': 1, 'w_log': 3, 'w_rf': 2}. Best is trial 12 with value: 0.5366594393609555.\n",
      "[I 2025-04-01 11:08:44,423] Trial 24 finished with value: 0.5243800743997717 and parameters: {'svm_C': 3.0103377791076658, 'svm_gamma': 0.06481589896211397, 'rf_n_estimators': 57, 'rf_max_depth': 5, 'w_svm': 2, 'w_log': 3, 'w_rf': 1}. Best is trial 12 with value: 0.5366594393609555.\n",
      "[I 2025-04-01 11:08:44,955] Trial 25 finished with value: 0.5273264290105063 and parameters: {'svm_C': 1.8978819984773345, 'svm_gamma': 0.021642657265228776, 'rf_n_estimators': 79, 'rf_max_depth': 4, 'w_svm': 1, 'w_log': 2, 'w_rf': 2}. Best is trial 12 with value: 0.5366594393609555.\n",
      "[I 2025-04-01 11:08:45,456] Trial 26 finished with value: 0.5160304720918596 and parameters: {'svm_C': 1.1258887453396054, 'svm_gamma': 0.0011310550537227421, 'rf_n_estimators': 65, 'rf_max_depth': 5, 'w_svm': 1, 'w_log': 3, 'w_rf': 1}. Best is trial 12 with value: 0.5366594393609555.\n",
      "[I 2025-04-01 11:08:46,021] Trial 27 finished with value: 0.505109858673206 and parameters: {'svm_C': 1.70409319408087, 'svm_gamma': 0.06983350041694396, 'rf_n_estimators': 84, 'rf_max_depth': 4, 'w_svm': 2, 'w_log': 2, 'w_rf': 3}. Best is trial 12 with value: 0.5366594393609555.\n",
      "[I 2025-04-01 11:08:46,519] Trial 28 finished with value: 0.5256715828123505 and parameters: {'svm_C': 3.3637529717033634, 'svm_gamma': 0.04054227725909051, 'rf_n_estimators': 71, 'rf_max_depth': 3, 'w_svm': 1, 'w_log': 3, 'w_rf': 2}. Best is trial 12 with value: 0.5366594393609555.\n",
      "[I 2025-04-01 11:08:47,085] Trial 29 finished with value: 0.5190933792788158 and parameters: {'svm_C': 2.135161876675622, 'svm_gamma': 0.028589551172656453, 'rf_n_estimators': 77, 'rf_max_depth': 6, 'w_svm': 1, 'w_log': 3, 'w_rf': 2}. Best is trial 12 with value: 0.5366594393609555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Best Hyperparameters from Optuna]\n",
      "  - svm_C: 1.6790490502143491\n",
      "  - svm_gamma: 0.085645640201387\n",
      "  - rf_n_estimators: 74\n",
      "  - rf_max_depth: 5\n",
      "  - w_svm: 1\n",
      "  - w_log: 3\n",
      "  - w_rf: 1\n",
      "\n",
      "[최종 VotingClassifier 앙상블 성능 평가]\n",
      "훈련 정확도: 0.641\n",
      "테스트 정확도: 0.483\n",
      "\n",
      "Confusion Matrix:\n",
      "                 Predicted: 0  Predicted: 1\n",
      "Actual: 0 (비이탈)            48            50\n",
      "Actual: 1 (이탈)             55            50\n",
      "\n",
      "Classification Report:\n",
      "              precision  recall  f1-score  support\n",
      "0                 0.466   0.490     0.478   98.000\n",
      "1                 0.500   0.476     0.488  105.000\n",
      "accuracy          0.483   0.483     0.483    0.483\n",
      "macro avg         0.483   0.483     0.483  203.000\n",
      "weighted avg      0.484   0.483     0.483  203.000\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "\n",
    "# 3. 수치형 피처 스케일링\n",
    "numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "# 4. NumPy 배열로 변환 (교차 검증 시 인덱스 문제 해결을 위해)\n",
    "X_train_arr = X_train_scaled.values\n",
    "y_train_arr = y_train.values\n",
    "X_test_arr = X_test_scaled.values\n",
    "y_test_arr = y_test.values\n",
    "\n",
    "# 5. Optuna Objective 함수 (VotingClassifier 앙상블 튜닝)\n",
    "def objective(trial):\n",
    "    # SVM 하이퍼파라미터\n",
    "    svm_C = trial.suggest_float(\"svm_C\", 0.1, 5.0, log=True)\n",
    "    svm_gamma = trial.suggest_float(\"svm_gamma\", 0.001, 0.1, log=True)\n",
    "    \n",
    "    # RandomForest 하이퍼파라미터\n",
    "    rf_n_estimators = trial.suggest_int(\"rf_n_estimators\", 50, 100)\n",
    "    rf_max_depth = trial.suggest_int(\"rf_max_depth\", 3, 6)\n",
    "    \n",
    "    # Voting 가중치\n",
    "    w_svm = trial.suggest_int(\"w_svm\", 1, 3)\n",
    "    w_log = trial.suggest_int(\"w_log\", 1, 3)\n",
    "    w_rf  = trial.suggest_int(\"w_rf\", 1, 3)\n",
    "    \n",
    "    # 개별 모델 정의\n",
    "    svm = SVC(\n",
    "        C=svm_C,\n",
    "        gamma=svm_gamma,\n",
    "        kernel='rbf',\n",
    "        class_weight='balanced',\n",
    "        probability=True,\n",
    "        random_state=0\n",
    "    )\n",
    "    \n",
    "    logreg = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=0)\n",
    "    \n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=rf_n_estimators,\n",
    "        max_depth=rf_max_depth,\n",
    "        max_features='sqrt',\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Voting 앙상블 구성 (soft voting)\n",
    "    voting_model = VotingClassifier(\n",
    "        estimators=[('svm', svm), ('logreg', logreg), ('rf', rf)],\n",
    "        voting='soft',\n",
    "        weights=[w_svm, w_log, w_rf]\n",
    "    )\n",
    "    \n",
    "    # Stratified KFold 교차 검증 (NumPy 배열 → DataFrame로 복원)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    for train_idx, valid_idx in cv.split(X_train_arr, y_train_arr):\n",
    "        # NumPy 배열 슬라이싱\n",
    "        X_tr, X_val = X_train_arr[train_idx], X_train_arr[valid_idx]\n",
    "        y_tr, y_val = y_train_arr[train_idx], y_train_arr[valid_idx]\n",
    "        # DataFrame으로 복원 (원래 컬럼 유지)\n",
    "        X_tr_df = pd.DataFrame(X_tr, columns=X_train_scaled.columns)\n",
    "        X_val_df = pd.DataFrame(X_val, columns=X_train_scaled.columns)\n",
    "        \n",
    "        voting_model.fit(X_tr_df, y_tr)\n",
    "        preds = voting_model.predict(X_val_df)\n",
    "        scores.append(f1_score(y_val, preds, average='weighted'))\n",
    "    return np.mean(scores)\n",
    "\n",
    "# 6. Optuna 스터디 실행\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# 7. 최적 하이퍼파라미터 출력\n",
    "best_params = study.best_trial.params\n",
    "print(\"\\n[Best Hyperparameters from Optuna]\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"  - {k}: {v}\")\n",
    "\n",
    "# 8. 최적 파라미터로 개별 모델 재정의\n",
    "svm_best = SVC(\n",
    "    C=best_params['svm_C'],\n",
    "    gamma=best_params['svm_gamma'],\n",
    "    kernel='rbf',\n",
    "    class_weight='balanced',\n",
    "    probability=True,\n",
    "    random_state=0\n",
    ")\n",
    "logreg_best = LogisticRegression(max_iter=1000, class_weight='balanced',  random_state=0)\n",
    "rf_best = RandomForestClassifier(\n",
    "    n_estimators=best_params['rf_n_estimators'],\n",
    "    max_depth=best_params['rf_max_depth'],\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 9. 최적 가중치를 적용한 VotingClassifier 구성\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[('svm', svm_best), ('logreg', logreg_best), ('rf', rf_best)],\n",
    "    voting='soft',\n",
    "    weights=[best_params['w_svm'], best_params['w_log'], best_params['w_rf']]\n",
    ")\n",
    "\n",
    "# 10. 최종 모델 학습 및 평가 (NumPy 배열이 아닌 DataFrame 사용)\n",
    "voting_model.fit(X_train_scaled, y_train)\n",
    "y_pred = voting_model.predict(X_test_scaled)\n",
    "\n",
    "train_acc = accuracy_score(y_train, voting_model.predict(X_train_scaled))\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# 11. 결과 출력\n",
    "print(\"\\n[최종 VotingClassifier 앙상블 성능 평가]\")\n",
    "print(f\"훈련 정확도: {train_acc:.3f}\")\n",
    "print(f\"테스트 정확도: {test_acc:.3f}\\n\")\n",
    "\n",
    "conf_df = pd.DataFrame(\n",
    "    conf_mat,\n",
    "    index=[\"Actual: 0 (비이탈)\", \"Actual: 1 (이탈)\"],\n",
    "    columns=[\"Predicted: 0\", \"Predicted: 1\"]\n",
    ")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_df)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "report_df = pd.DataFrame(report_dict).transpose().round(3)\n",
    "print(report_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
